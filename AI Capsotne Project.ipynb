{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><h1>Pre-trained-Models with PyTorch </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n",
    "<ul>\n",
    "<li>change the output layer</li>\n",
    "<li> train the model</li> \n",
    "<li>  identify  several  misclassified samples</li> \n",
    " </ul>\n",
    "You will take several screenshots of your work and share your notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
    "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
    "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
    " </div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-24 10:36:26--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2598656062 (2.4G) [application/zip]\n",
      "Saving to: ‘Positive_tensors.zip’\n",
      "\n",
      "100%[====================================>] 2,598,656,062 45.0MB/s   in 59s    \n",
      "\n",
      "2020-04-24 10:37:25 (42.1 MB/s) - ‘Positive_tensors.zip’ saved [2598656062/2598656062]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-24 10:39:51--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2111408108 (2.0G) [application/zip]\n",
      "Saving to: ‘Negative_tensors.zip’\n",
      "\n",
      "100%[====================================>] 2,111,408,108 45.1MB/s   in 44s    \n",
      "\n",
      "2020-04-24 10:40:35 (45.7 MB/s) - ‘Negative_tensors.zip’ saved [2111408108/2111408108]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
    "!unzip -q Negative_tensors.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will install torchvision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/51/aa2770a70f612ce9a2fc7da3a1a93f9ecf8746788256fed6b691f9b31ca9/torchvision-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6MB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (5.4.1)\n",
      "Collecting torch==1.5.0 (from torchvision)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/70/54e9fb010fe1547bc4774716f11ececb81ae5b306c05f090f4461ee13205/torch-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (752.0MB)\n",
      "\u001b[K     |████████████████████████████████| 752.0MB 19kB/s s eta 0:00:010MB 42.9MB/s eta 0:00:17:00:06MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (1.15.4)\n",
      "Requirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch==1.5.0->torchvision) (0.17.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.5.0 torchvision-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd3fc08b6b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pandas\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"/home/dsxuser/work\"\n",
    "        positive=\"Positive_tensors\"\n",
    "        negative='Negative_tensors'\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:30000]\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)     \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        image=torch.load(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "                  \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two dataset objects, one for the training data and one for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train=True)\n",
    "validation_dataset = Dataset(train=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Question 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/dsxuser/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6b712a81b7462fb711447959a7a186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46827520), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "\n",
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hidden = 512\n",
    "d_out = 2\n",
    "\n",
    "model.fc = nn.Linear(d_hidden, d_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2: Train the Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question you will train your, model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0342, -0.0255,  0.0249,  ...,  0.0130, -0.0365, -0.0426],\n",
      "        [ 0.0411, -0.0204,  0.0384,  ...,  0.0156, -0.0340,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0074, 0.0091], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Verify the parameters whose requires_grad are True\n",
    "for param in model.parameters():\n",
    "  if param.requires_grad:\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in training set :  30000\n",
      "Number of items in testing set :  10000\n",
      "------------------------------\n",
      "Iteration (train phase) 1/300\n",
      "Finished in 6.110520124435425 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 2/300\n",
      "Finished in 12.497721672058105 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 3/300\n",
      "Finished in 19.095232486724854 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 4/300\n",
      "Finished in 25.864897966384888 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 5/300\n",
      "Finished in 32.46548867225647 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 6/300\n",
      "Finished in 39.0147602558136 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 7/300\n",
      "Finished in 45.5710825920105 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 8/300\n",
      "Finished in 52.1403067111969 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 9/300\n",
      "Finished in 58.80852675437927 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 10/300\n",
      "Finished in 65.49220657348633 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 11/300\n",
      "Finished in 72.11736750602722 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 12/300\n",
      "Finished in 78.68362164497375 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 13/300\n",
      "Finished in 85.3758864402771 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 14/300\n",
      "Finished in 92.09141778945923 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 15/300\n",
      "Finished in 98.7392590045929 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 16/300\n",
      "Finished in 105.43900394439697 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 17/300\n",
      "Finished in 112.11188292503357 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 18/300\n",
      "Finished in 118.72268438339233 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 19/300\n",
      "Finished in 125.41785860061646 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 20/300\n",
      "Finished in 132.0944483280182 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 21/300\n",
      "Finished in 138.80156326293945 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 22/300\n",
      "Finished in 145.49331259727478 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 23/300\n",
      "Finished in 152.14502501487732 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 24/300\n",
      "Finished in 158.8124520778656 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 25/300\n",
      "Finished in 165.46836018562317 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 26/300\n",
      "Finished in 172.3035922050476 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 27/300\n",
      "Finished in 179.00443935394287 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 28/300\n",
      "Finished in 185.71389842033386 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 29/300\n",
      "Finished in 192.3650004863739 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 30/300\n",
      "Finished in 199.03991508483887 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 31/300\n",
      "Finished in 205.7696409225464 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 32/300\n",
      "Finished in 212.57696771621704 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 33/300\n",
      "Finished in 219.21217679977417 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 34/300\n",
      "Finished in 225.90803742408752 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 35/300\n",
      "Finished in 232.59643626213074 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 36/300\n",
      "Finished in 239.29784607887268 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 37/300\n",
      "Finished in 246.07837200164795 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 38/300\n",
      "Finished in 252.72208309173584 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 39/300\n",
      "Finished in 259.46423721313477 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 40/300\n",
      "Finished in 266.08900117874146 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 41/300\n",
      "Finished in 272.7992329597473 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 42/300\n",
      "Finished in 279.55959010124207 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 43/300\n",
      "Finished in 286.2657346725464 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 44/300\n",
      "Finished in 292.97893142700195 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 45/300\n",
      "Finished in 299.6906404495239 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 46/300\n",
      "Finished in 306.38306307792664 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 47/300\n",
      "Finished in 313.13728499412537 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 48/300\n",
      "Finished in 319.7664215564728 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 49/300\n",
      "Finished in 326.41083574295044 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 50/300\n",
      "Finished in 333.1654236316681 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 51/300\n",
      "Finished in 339.91299176216125 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 52/300\n",
      "Finished in 346.63371992111206 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 53/300\n",
      "Finished in 353.17005157470703 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 54/300\n",
      "Finished in 359.82670521736145 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 55/300\n",
      "Finished in 366.3647403717041 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 56/300\n",
      "Finished in 373.01070499420166 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 57/300\n",
      "Finished in 379.7072958946228 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 58/300\n",
      "Finished in 386.3994414806366 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 59/300\n",
      "Finished in 392.9989404678345 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 60/300\n",
      "Finished in 399.60744428634644 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 61/300\n",
      "Finished in 406.2885277271271 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 62/300\n",
      "Finished in 412.88378071784973 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 63/300\n",
      "Finished in 419.4233260154724 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 64/300\n",
      "Finished in 426.0289840698242 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 65/300\n",
      "Finished in 432.6823172569275 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 66/300\n",
      "Finished in 439.41798734664917 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 67/300\n",
      "Finished in 446.29842805862427 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 68/300\n",
      "Finished in 453.14716958999634 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 69/300\n",
      "Finished in 460.0451476573944 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 70/300\n",
      "Finished in 466.7768704891205 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 71/300\n",
      "Finished in 473.6777994632721 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 72/300\n",
      "Finished in 480.4193346500397 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 73/300\n",
      "Finished in 487.19020414352417 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 74/300\n",
      "Finished in 493.89741253852844 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 75/300\n",
      "Finished in 500.87328028678894 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 76/300\n",
      "Finished in 507.578245639801 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 77/300\n",
      "Finished in 514.23486161232 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 78/300\n",
      "Finished in 521.0635871887207 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 79/300\n",
      "Finished in 527.7209458351135 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 80/300\n",
      "Finished in 534.4052412509918 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 81/300\n",
      "Finished in 541.1518948078156 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 82/300\n",
      "Finished in 548.0397322177887 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 83/300\n",
      "Finished in 554.7634289264679 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 84/300\n",
      "Finished in 561.4429986476898 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 85/300\n",
      "Finished in 568.109091758728 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 86/300\n",
      "Finished in 574.826226234436 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 87/300\n",
      "Finished in 581.5538442134857 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 88/300\n",
      "Finished in 588.5988669395447 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 89/300\n",
      "Finished in 595.305314540863 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 90/300\n",
      "Finished in 601.9888279438019 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 91/300\n",
      "Finished in 608.5635216236115 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 92/300\n",
      "Finished in 615.2489387989044 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 93/300\n",
      "Finished in 621.951281785965 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 94/300\n",
      "Finished in 628.5692889690399 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 95/300\n",
      "Finished in 635.3727707862854 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 96/300\n",
      "Finished in 642.1994514465332 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 97/300\n",
      "Finished in 648.9232287406921 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 98/300\n",
      "Finished in 655.6655020713806 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 99/300\n",
      "Finished in 662.3636419773102 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 100/300\n",
      "Finished in 669.0749125480652 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 101/300\n",
      "Finished in 675.8388166427612 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 102/300\n",
      "Finished in 683.5118160247803 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 103/300\n",
      "Finished in 690.2303943634033 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 104/300\n",
      "Finished in 696.7977073192596 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 105/300\n",
      "Finished in 703.6777715682983 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 106/300\n",
      "Finished in 710.590943813324 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 107/300\n",
      "Finished in 717.3450863361359 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 108/300\n",
      "Finished in 723.9823825359344 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 109/300\n",
      "Finished in 730.6244230270386 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 110/300\n",
      "Finished in 737.3718826770782 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 111/300\n",
      "Finished in 744.1098067760468 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 112/300\n",
      "Finished in 750.8627507686615 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 113/300\n",
      "Finished in 757.6565523147583 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 114/300\n",
      "Finished in 764.4460442066193 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 115/300\n",
      "Finished in 771.1823499202728 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 116/300\n",
      "Finished in 777.7758445739746 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 117/300\n",
      "Finished in 784.401695728302 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 118/300\n",
      "Finished in 791.0974378585815 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 119/300\n",
      "Finished in 797.8653872013092 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 120/300\n",
      "Finished in 804.6463153362274 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 121/300\n",
      "Finished in 811.4451532363892 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 122/300\n",
      "Finished in 818.2548444271088 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 123/300\n",
      "Finished in 824.9918823242188 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 124/300\n",
      "Finished in 831.8321347236633 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 125/300\n",
      "Finished in 838.4732689857483 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 126/300\n",
      "Finished in 845.2437722682953 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 127/300\n",
      "Finished in 851.9904193878174 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 128/300\n",
      "Finished in 858.5792808532715 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 129/300\n",
      "Finished in 865.2195177078247 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 130/300\n",
      "Finished in 871.9778385162354 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 131/300\n",
      "Finished in 878.7209763526917 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 132/300\n",
      "Finished in 885.3891055583954 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 133/300\n",
      "Finished in 892.1170797348022 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 134/300\n",
      "Finished in 898.8463597297668 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 135/300\n",
      "Finished in 905.4978580474854 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 136/300\n",
      "Finished in 912.1300683021545 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 137/300\n",
      "Finished in 918.8780989646912 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 138/300\n",
      "Finished in 925.514232635498 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 139/300\n",
      "Finished in 932.2881405353546 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 140/300\n",
      "Finished in 939.0088877677917 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 141/300\n",
      "Finished in 945.813098192215 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 142/300\n",
      "Finished in 952.5146222114563 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 143/300\n",
      "Finished in 959.2678711414337 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 144/300\n",
      "Finished in 966.070151090622 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 145/300\n",
      "Finished in 972.8230450153351 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 146/300\n",
      "Finished in 979.5600001811981 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 147/300\n",
      "Finished in 986.3409073352814 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 148/300\n",
      "Finished in 993.092383146286 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 149/300\n",
      "Finished in 999.8102276325226 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 150/300\n",
      "Finished in 1006.5612654685974 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 151/300\n",
      "Finished in 1013.466392993927 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 152/300\n",
      "Finished in 1020.0517580509186 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 153/300\n",
      "Finished in 1026.634022951126 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 154/300\n",
      "Finished in 1033.3515617847443 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 155/300\n",
      "Finished in 1040.057627916336 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 156/300\n",
      "Finished in 1046.6603496074677 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 157/300\n",
      "Finished in 1053.376582145691 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 158/300\n",
      "Finished in 1060.0051891803741 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 159/300\n",
      "Finished in 1066.8332056999207 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 160/300\n",
      "Finished in 1073.6717104911804 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 161/300\n",
      "Finished in 1080.3975856304169 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 162/300\n",
      "Finished in 1087.2248854637146 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 163/300\n",
      "Finished in 1093.9633655548096 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 164/300\n",
      "Finished in 1101.120977640152 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 165/300\n",
      "Finished in 1107.8157391548157 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 166/300\n",
      "Finished in 1114.537981748581 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 167/300\n",
      "Finished in 1121.3430235385895 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 168/300\n",
      "Finished in 1128.1287384033203 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 169/300\n",
      "Finished in 1134.8714056015015 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 170/300\n",
      "Finished in 1141.570707321167 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 171/300\n",
      "Finished in 1148.2883241176605 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 172/300\n",
      "Finished in 1154.9873688220978 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 173/300\n",
      "Finished in 1161.796528339386 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 174/300\n",
      "Finished in 1168.6563701629639 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 175/300\n",
      "Finished in 1175.5382404327393 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 176/300\n",
      "Finished in 1182.287493467331 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 177/300\n",
      "Finished in 1189.0294215679169 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 178/300\n",
      "Finished in 1195.775050163269 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 179/300\n",
      "Finished in 1202.38734292984 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 180/300\n",
      "Finished in 1209.1651945114136 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 181/300\n",
      "Finished in 1215.975937128067 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 182/300\n",
      "Finished in 1222.6972317695618 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 183/300\n",
      "Finished in 1229.7558579444885 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 184/300\n",
      "Finished in 1236.4551830291748 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 185/300\n",
      "Finished in 1243.1979570388794 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 186/300\n",
      "Finished in 1250.00315451622 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 187/300\n",
      "Finished in 1256.6569330692291 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 188/300\n",
      "Finished in 1263.5317933559418 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 189/300\n",
      "Finished in 1270.2357366085052 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 190/300\n",
      "Finished in 1277.0749781131744 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 191/300\n",
      "Finished in 1283.8685522079468 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 192/300\n",
      "Finished in 1290.4782302379608 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 193/300\n",
      "Finished in 1297.1937403678894 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 194/300\n",
      "Finished in 1303.866569519043 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 195/300\n",
      "Finished in 1310.6744878292084 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 196/300\n",
      "Finished in 1317.459870815277 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 197/300\n",
      "Finished in 1324.1407420635223 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 198/300\n",
      "Finished in 1331.3027184009552 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 199/300\n",
      "Finished in 1338.0703072547913 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 200/300\n",
      "Finished in 1344.7227761745453 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 201/300\n",
      "Finished in 1351.4728462696075 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 202/300\n",
      "Finished in 1358.1103162765503 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 203/300\n",
      "Finished in 1364.86923289299 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 204/300\n",
      "Finished in 1371.7772510051727 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 205/300\n",
      "Finished in 1378.4546613693237 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 206/300\n",
      "Finished in 1385.1002357006073 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 207/300\n",
      "Finished in 1391.8228018283844 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 208/300\n",
      "Finished in 1398.4791896343231 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 209/300\n",
      "Finished in 1405.2671291828156 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 210/300\n",
      "Finished in 1411.963346004486 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 211/300\n",
      "Finished in 1418.668779373169 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 212/300\n",
      "Finished in 1425.3824210166931 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 213/300\n",
      "Finished in 1432.1727228164673 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 214/300\n",
      "Finished in 1438.9516153335571 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 215/300\n",
      "Finished in 1445.6407918930054 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 216/300\n",
      "Finished in 1452.3632247447968 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 217/300\n",
      "Finished in 1459.2333686351776 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 218/300\n",
      "Finished in 1466.6043000221252 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 219/300\n",
      "Finished in 1473.9730467796326 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 220/300\n",
      "Finished in 1481.443749666214 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 221/300\n",
      "Finished in 1489.0426843166351 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 222/300\n",
      "Finished in 1496.4073133468628 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 223/300\n",
      "Finished in 1503.657356262207 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 224/300\n",
      "Finished in 1510.8580901622772 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 225/300\n",
      "Finished in 1518.0897769927979 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 226/300\n",
      "Finished in 1525.8282136917114 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 227/300\n",
      "Finished in 1533.1806647777557 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 228/300\n",
      "Finished in 1540.3788545131683 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 229/300\n",
      "Finished in 1547.7142848968506 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 230/300\n",
      "Finished in 1554.9793627262115 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 231/300\n",
      "Finished in 1562.3462436199188 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 232/300\n",
      "Finished in 1569.7473652362823 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 233/300\n",
      "Finished in 1577.3721511363983 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 234/300\n",
      "Finished in 1584.6314189434052 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 235/300\n",
      "Finished in 1592.0222625732422 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 236/300\n",
      "Finished in 1599.4102165699005 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 237/300\n",
      "Finished in 1606.7027914524078 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 238/300\n",
      "Finished in 1613.921704530716 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 239/300\n",
      "Finished in 1621.2311441898346 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 240/300\n",
      "Finished in 1628.586269378662 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 241/300\n",
      "Finished in 1635.9981360435486 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 242/300\n",
      "Finished in 1643.4736981391907 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 243/300\n",
      "Finished in 1650.94389128685 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 244/300\n",
      "Finished in 1658.4207963943481 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 245/300\n",
      "Finished in 1665.746241569519 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 246/300\n",
      "Finished in 1673.0407710075378 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 247/300\n",
      "Finished in 1680.2217314243317 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 248/300\n",
      "Finished in 1687.6392381191254 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 249/300\n",
      "Finished in 1694.9240508079529 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 250/300\n",
      "Finished in 1702.2755858898163 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 251/300\n",
      "Finished in 1709.6763615608215 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 252/300\n",
      "Finished in 1716.9499952793121 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 253/300\n",
      "Finished in 1724.4334409236908 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 254/300\n",
      "Finished in 1731.7829778194427 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 255/300\n",
      "Finished in 1739.20610165596 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 256/300\n",
      "Finished in 1746.5384199619293 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 257/300\n",
      "Finished in 1753.8645708560944 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 258/300\n",
      "Finished in 1761.1244449615479 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 259/300\n",
      "Finished in 1768.5514068603516 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 260/300\n",
      "Finished in 1775.8184652328491 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 261/300\n",
      "Finished in 1783.116852760315 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 262/300\n",
      "Finished in 1790.4088883399963 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 263/300\n",
      "Finished in 1797.800055027008 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 264/300\n",
      "Finished in 1805.1842033863068 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 265/300\n",
      "Finished in 1812.5221219062805 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 266/300\n",
      "Finished in 1820.0301756858826 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 267/300\n",
      "Finished in 1827.3576436042786 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 268/300\n",
      "Finished in 1834.7378158569336 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 269/300\n",
      "Finished in 1842.2199380397797 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 270/300\n",
      "Finished in 1849.6036269664764 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 271/300\n",
      "Finished in 1856.9211966991425 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 272/300\n",
      "Finished in 1864.3054814338684 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 273/300\n",
      "Finished in 1871.5668048858643 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 274/300\n",
      "Finished in 1878.9643392562866 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 275/300\n",
      "Finished in 1886.4471521377563 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 276/300\n",
      "Finished in 1893.8914737701416 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 277/300\n",
      "Finished in 1901.2600555419922 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 278/300\n",
      "Finished in 1908.5532429218292 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 279/300\n",
      "Finished in 1916.0528349876404 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 280/300\n",
      "Finished in 1923.3081266880035 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 281/300\n",
      "Finished in 1930.6412580013275 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 282/300\n",
      "Finished in 1938.0359015464783 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 283/300\n",
      "Finished in 1945.4128386974335 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 284/300\n",
      "Finished in 1952.9035212993622 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 285/300\n",
      "Finished in 1960.3047246932983 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 286/300\n",
      "Finished in 1967.6289298534393 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 287/300\n",
      "Finished in 1975.0226995944977 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 288/300\n",
      "Finished in 1982.279286146164 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 289/300\n",
      "Finished in 1989.6821570396423 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 290/300\n",
      "Finished in 1996.961757659912 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 291/300\n",
      "Finished in 2004.2282009124756 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 292/300\n",
      "Finished in 2011.538169145584 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 293/300\n",
      "Finished in 2018.9047334194183 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 294/300\n",
      "Finished in 2026.3389563560486 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 295/300\n",
      "Finished in 2033.6253061294556 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 296/300\n",
      "Finished in 2040.8829596042633 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 297/300\n",
      "Finished in 2048.194071292877 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 298/300\n",
      "Finished in 2055.584537267685 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 299/300\n",
      "Finished in 2062.973346233368 (s)\n",
      "------------------------------\n",
      "Iteration (train phase) 300/300\n",
      "Finished in 2070.339840888977 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 1/100\n",
      "Finished in 2077.28227353096 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 2/100\n",
      "Finished in 2084.1202244758606 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 3/100\n",
      "Finished in 2091.0835058689117 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 4/100\n",
      "Finished in 2097.992784500122 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 5/100\n",
      "Finished in 2104.8405787944794 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 6/100\n",
      "Finished in 2111.6288044452667 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 7/100\n",
      "Finished in 2118.4559800624847 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 8/100\n",
      "Finished in 2125.375375032425 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 9/100\n",
      "Finished in 2132.3465588092804 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 10/100\n",
      "Finished in 2139.347670316696 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 11/100\n",
      "Finished in 2146.218586206436 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 12/100\n",
      "Finished in 2153.1478991508484 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 13/100\n",
      "Finished in 2160.0345141887665 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 14/100\n",
      "Finished in 2167.0283513069153 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 15/100\n",
      "Finished in 2173.985092639923 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 16/100\n",
      "Finished in 2180.833265066147 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 17/100\n",
      "Finished in 2187.8471064567566 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 18/100\n",
      "Finished in 2194.6788306236267 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 19/100\n",
      "Finished in 2201.6122148036957 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 20/100\n",
      "Finished in 2208.4969630241394 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 21/100\n",
      "Finished in 2215.4295015335083 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 22/100\n",
      "Finished in 2222.3328108787537 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 23/100\n",
      "Finished in 2229.2271206378937 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 24/100\n",
      "Finished in 2236.1583421230316 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 25/100\n",
      "Finished in 2243.0253381729126 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 26/100\n",
      "Finished in 2249.9986474514008 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 27/100\n",
      "Finished in 2256.790241241455 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 28/100\n",
      "Finished in 2263.729804992676 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 29/100\n",
      "Finished in 2270.6656234264374 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 30/100\n",
      "Finished in 2277.4639732837677 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 31/100\n",
      "Finished in 2284.3453075885773 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 32/100\n",
      "Finished in 2291.155797958374 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 33/100\n",
      "Finished in 2298.0197134017944 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 34/100\n",
      "Finished in 2304.8569917678833 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 35/100\n",
      "Finished in 2311.770970106125 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 36/100\n",
      "Finished in 2318.648773431778 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 37/100\n",
      "Finished in 2325.3896338939667 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 38/100\n",
      "Finished in 2332.2026374340057 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 39/100\n",
      "Finished in 2339.072658777237 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 40/100\n",
      "Finished in 2345.803546667099 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 41/100\n",
      "Finished in 2352.5865137577057 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 42/100\n",
      "Finished in 2359.4893786907196 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 43/100\n",
      "Finished in 2366.2587361335754 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 44/100\n",
      "Finished in 2373.1380712985992 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 45/100\n",
      "Finished in 2380.0165526866913 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 46/100\n",
      "Finished in 2386.7947523593903 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 47/100\n",
      "Finished in 2393.602108478546 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 48/100\n",
      "Finished in 2400.33952832222 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 49/100\n",
      "Finished in 2407.1084439754486 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 50/100\n",
      "Finished in 2413.8693718910217 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 51/100\n",
      "Finished in 2420.7872273921967 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 52/100\n",
      "Finished in 2427.7557027339935 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 53/100\n",
      "Finished in 2434.6412818431854 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 54/100\n",
      "Finished in 2441.5241346359253 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 55/100\n",
      "Finished in 2448.2708687782288 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 56/100\n",
      "Finished in 2455.0686087608337 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 57/100\n",
      "Finished in 2461.9353625774384 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 58/100\n",
      "Finished in 2468.6984481811523 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 59/100\n",
      "Finished in 2475.477546930313 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 60/100\n",
      "Finished in 2482.3347992897034 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 61/100\n",
      "Finished in 2489.1344125270844 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 62/100\n",
      "Finished in 2496.0541381835938 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 63/100\n",
      "Finished in 2502.9921424388885 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 64/100\n",
      "Finished in 2509.8807525634766 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 65/100\n",
      "Finished in 2516.8029429912567 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 66/100\n",
      "Finished in 2523.5535542964935 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 67/100\n",
      "Finished in 2530.425393819809 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 68/100\n",
      "Finished in 2537.323363304138 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 69/100\n",
      "Finished in 2544.16926074028 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 70/100\n",
      "Finished in 2551.4702067375183 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 71/100\n",
      "Finished in 2558.395974636078 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 72/100\n",
      "Finished in 2565.3018567562103 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 73/100\n",
      "Finished in 2572.111503601074 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 74/100\n",
      "Finished in 2578.9354577064514 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 75/100\n",
      "Finished in 2585.8993496894836 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 76/100\n",
      "Finished in 2592.691181898117 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 77/100\n",
      "Finished in 2599.6565747261047 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 78/100\n",
      "Finished in 2606.4464116096497 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 79/100\n",
      "Finished in 2613.3367264270782 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 80/100\n",
      "Finished in 2620.176944255829 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 81/100\n",
      "Finished in 2627.0278146266937 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 82/100\n",
      "Finished in 2633.790049791336 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 83/100\n",
      "Finished in 2640.494190454483 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 84/100\n",
      "Finished in 2647.3174500465393 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 85/100\n",
      "Finished in 2654.1660611629486 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 86/100\n",
      "Finished in 2661.0324466228485 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 87/100\n",
      "Finished in 2667.9707436561584 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 88/100\n",
      "Finished in 2675.0246682167053 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 89/100\n",
      "Finished in 2681.901611804962 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 90/100\n",
      "Finished in 2688.7986102104187 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 91/100\n",
      "Finished in 2695.709557533264 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 92/100\n",
      "Finished in 2702.4541726112366 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 93/100\n",
      "Finished in 2709.42364692688 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 94/100\n",
      "Finished in 2716.325987815857 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 95/100\n",
      "Finished in 2723.227430343628 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 96/100\n",
      "Finished in 2730.0794775485992 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 97/100\n",
      "Finished in 2736.906327724457 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 98/100\n",
      "Finished in 2743.8844680786133 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 99/100\n",
      "Finished in 2750.720194339752 (s)\n",
      "------------------------------\n",
      "Iteration (validation phase) 100/100\n",
      "Finished in 2757.511766433716 (s)\n",
      "Epoch 1 - accuracy: 0.995\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-092975abe612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mmodel_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"resnet18_trained_model_epoch_{}.pth\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_path' is not defined"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "accuracy = 0\n",
    "correct = 0\n",
    "N_test = len(validation_dataset)\n",
    "N_train = len(train_dataset)\n",
    "start_time = time.time()\n",
    "#n_epochs\n",
    "\n",
    "print(\"Number of items in training set : \", N_train)\n",
    "print(\"Number of items in testing set : \", N_test)\n",
    "\n",
    "running_loss = 0\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):        \n",
    "        print('-' * 30)\n",
    "        print('Iteration (train phase) {}/{}'.format(i+1, int(N_train/batch_size)))\n",
    "\n",
    "            \n",
    "        # set model to train \n",
    "        model.train() \n",
    "        \n",
    "        # clear gradient \n",
    "        optimizer.zero_grad()\n",
    "     \n",
    "        # make a prediction \n",
    "        z = model(x)\n",
    "   \n",
    "        # calculate loss \n",
    "        loss = criterion(z, y) \n",
    "        # loss.requires_grad = True\n",
    "    \n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.data)\n",
    "        print(\"Finished in {} (s)\".format(time.time()-start_time))\n",
    "    # end for\n",
    "        \n",
    "    correct=0\n",
    "    for i, (x_test, y_test) in enumerate(validation_loader):\n",
    "        print('-' * 30)\n",
    "        print('Iteration (validation phase) {}/{}'.format(i+1, int(N_test/batch_size)))\n",
    "    \n",
    "        \n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "       \n",
    "        # make a prediction \n",
    "        z = model(x_test)\n",
    "        \n",
    "        # find max \n",
    "        _, yhat = torch.max(z.data, 1)\n",
    "       \n",
    "       \n",
    "        #Calculate misclassified  samples in mini-batch \n",
    "        #hint +=(yhat==y_test).sum().item()\n",
    "        correct += (yhat==y_test).sum().item()  \n",
    "        \n",
    "        print(\"Finished in {} (s)\".format(time.time()-start_time))\n",
    "    # end for\n",
    "    \n",
    "    accuracy=correct/N_test\n",
    "    print(\"Epoch %d - accuracy: %.3f\" % (epoch+1, accuracy))\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    print(\"-\" * 72)\n",
    "    \n",
    "    # Save model\n",
    "    model_file_path = model_path + \"resnet18_trained_model_epoch_{}.pth\".format(epoch+1)\n",
    "    torch.save(model.state_dict(), model_file_path)\n",
    "    \n",
    "    # Duration for epoch\n",
    "    print(\"Finished epoch {} in {} (s).\".format(epoch+1, time.time()-start_time))\n",
    "# end for\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAELCAYAAAA2mZrgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8W/W9//HXR5LlvVfikZ2QRRISJxD2JowChTJvf90XuC3dt/fSRVtK721LS29puZdSCi2UltUCYYYRRiAkxIEMnOkkTuwM771kWd/fH+foWHbkxAlWZEef5+ORh6WjI/mrKDlvfbcYY1BKKaUAXNEugFJKqZFDQ0EppZRDQ0EppZRDQ0EppZRDQ0EppZRDQ0EppZQjoqEgIktEZKuIlIvIbYOcc62IbBKRMhH5WyTLo5RS6tAkUvMURMQNbAMuAKqANcANxphNIedMBZ4AzjXGNIpInjGmJiIFUkopdViRrCksAsqNMTuNMT7gMeCKAef8K3CvMaYRQANBKaWiK5KhUAhUhtyvso+FmgZME5F3RWSViCyJYHmUUkodhieCry1hjg1sq/IAU4GzgSJghYjMNsY09XshkZuAmwCSk5MXTJ8+ffhLq5RSx7G1a9fWGWNyD3deJEOhCigOuV8E7AtzzipjTA+wS0S2YoXEmtCTjDH3A/cDlJSUmNLS0ogVWimljkcisnso50Wy+WgNMFVEJoqIF7geWDrgnGeAcwBEJAerOWlnBMuklFLqECIWCsYYP3ArsAzYDDxhjCkTkTtE5HL7tGVAvYhsAt4AvmOMqY9UmZRSSh1axIakRoo2Hyml1JETkbXGmJLDnaczmpVSSjk0FJRSSjk0FJRSSjk0FJRSSjliKhTq2rp5dt3eaBdDKaVGrEhOXhtxLr1nBdUt3Zw1LZeMJG+0i6OUUiNOzNQUmjt7qG7pBqCl0x/l0iil1MgUM6Hwzw+qnNstXT1RLIlSSo1cMRMKJ0/M5uSJWQC0dWtNQSmlwomZUJhZkMYPLp0JQGuXhoJSSoUTM6EAkJJg9au3avORUkqFFVOhkGqHgjYfKaVUeDEZCtp8pJRS4cVUKMR73HjdLh19pJRSg4ipUACrttCmNQWllAorJkNBm4+UUiq8mAuFlASPjj5SSqlBxFwopMbH6egjpZQaROyFgjYfKaXUoGIuFFI0FJRSalAxFwppCXHap6CUUoOIuVBIiffQ1u3HGBPtoiil1IgTc6GQmuAhYOAfH+xlwm0v0NyptQallAqKuVDISrZ2XPvPf2wAoLqlK5rFUUqpESXmQqEwIxGA3oDVfOSSaJZGKaVGlpgLhQI7FIJ8fu1bUEqpoJgLhbEZCf3u+3oDUSqJUkqNPBENBRFZIiJbRaRcRG4L8/jnRKRWRNbZf74UyfKAtVJqbmq8c79HQ0EppRyeSL2wiLiBe4ELgCpgjYgsNcZsGnDq48aYWyNVjnAKMhKpbe0GwOfXUFBKqaBI1hQWAeXGmJ3GGB/wGHBFBH/fkBWF9CtoKCilVJ9IhkIhUBlyv8o+NtDVIrJBRJ4SkeIIlsdRENKvoH0KSinVJ5KhEG6w58ChPs8BE4wxc4DXgL+EfSGRm0SkVERKa2trP3bBxmUnO7e1pqCUUn0iGQpVQOg3/yJgX+gJxph6Y0y3ffePwIJwL2SMud8YU2KMKcnNzf3YBbtmQRG/uPpEQENBKaVCRTIU1gBTRWSiiHiB64GloSeIyNiQu5cDmyNYHkdCnJszplrhoqOPlFKqT8RGHxlj/CJyK7AMcAMPGmPKROQOoNQYsxT4mohcDviBBuBzkSrPQF6PlYfap6CUUn0iFgoAxpgXgRcHHLs95PZ3ge9GsgyDcUJBm4+UUsoRczOag7xurSkopdRAGgpaU1BKKUfMhoLLJXhcoh3NSikVImZDASDO7dKaglJKhYjpUPB6XPT06tLZSikVFNOhEOd20a01BaWUcsR0KMR7tPlIKaVCxXQoWM1HGgpKKRUU06EQ5xatKSilVIiYDgWvx6WT15RSKkRsh4Jbm4+UUipUTIeCjj5SSqn+YjoUtKNZKaX6i+lQ0CGpSinVX0yHgi5zoZRS/cV0KGjzkVJK9RfToaA1BaWU6i+mQ0HnKSilVH+xHQpaU1BKqX5iOxS0pqCUUv3Edii4dT8FpZQKFduh4HHRGzD0BjQYlFIKYjwU4tzW29d+BaWUssR0KHg9dihov4JSSgGxHgpuAbSmoJRSQbEdClpTUEqpfiIaCiKyRES2iki5iNx2iPM+JSJGREoiWZ6B8tISAKioaz+Wv1YppUasiIWCiLiBe4GLgZnADSIyM8x5qcDXgNWRKstgFk3IwuMS3imvO9a/WimlRqRI1hQWAeXGmJ3GGB/wGHBFmPN+CvwS6IpgWcJKjvdw0rgMVmooKKUUENlQKAQqQ+5X2cccInISUGyMeT6C5TikUyfnsGFvM80dPdEqglJKjRiRDAUJc8yZJSYiLuA3wLcP+0IiN4lIqYiU1tbWDmMRYVZBGsbAnoaOYX1dpZQajSIZClVAccj9ImBfyP1UYDbwpohUAKcAS8N1Nhtj7jfGlBhjSnJzc4e1kNkp8QDUtXcP6+sqpdRoFMlQWANMFZGJIuIFrgeWBh80xjQbY3KMMROMMROAVcDlxpjSCJbpIDkpXgDq23zH8tcqpdSIFLFQMMb4gVuBZcBm4AljTJmI3CEil0fq9x6pYE2hQWsKSimFJ5Ivbox5EXhxwLHbBzn37EiWZTDJXjfxHpfWFJRSihif0QwgIuSkxFOnoaCUUhoKANkpXuq1+UgppTQUALKTvdp8pJRSaCgAVmdzfZvWFJRSSkMBq/moprWbtbsbCegubEqpGKahAOQkx+MPGK7+v5V89qH36dGltJVSMUpDAUhN8Dg/V2yvY0NVc5RLpJRS0RHReQqjxZLZY6hv93FScQY3PrCali5dHE8pFZu0pgBkJHn5yjlTyE21Zje3dvmjXCKllIoODYUQqQlxALRqTUEpFaM0FEIE+xa0pqCUilUaCiGSvG7cLtGaglIqZmkohBARUuI9WlNQSsUsDYUBUhM0FJRSsUtDYYDUhDhtPlJKxSwNhQFSEzy0aE1BKRWjNBQGSNPmI6VUDNNQGECbj5RSsUxDYYDUBA9VjZ2c/F+vsbu+PdrFUUqpY0pDYYDgBLbqlm4+3NMU5dIopdSxpaEwQHCpC4BddVpTUErFFg2FAYI1BUCbj5RSMUdDYYAef98GOxX1HVEsiVJKHXsaCgOMSU8EIC81ngqtKSilYoyGwgAXzcrn9W+fxb+eMYmmjh6aOnzRLpJSSh0zGgoDiAiTc1OYkJMMaBOSUiq2DCkUROTrIpImlj+JyAcicmGkCxdNefYubA3t3VEuiVJKHTtDrSl8wRjTAlwI5AKfB35+uCeJyBIR2Soi5SJyW5jHbxGRjSKyTkTeEZGZR1T6CAqOQmrp1CUvlFKxY6ihIPbPS4CHjDHrQ46Ff4KIG7gXuBiYCdwQ5qL/N2PMicaYecAvgbuHXPIIS0u05iu06JIXSqkYMtRQWCsir2CFwjIRSQUCh3nOIqDcGLPTGOMDHgOuCD3Brn0EJQNmiOWJON2aUykVizyHPwWALwLzgJ3GmA4RycJqQjqUQqAy5H4VcPLAk0TkK8C3AC9w7hDLE3HxHjfxHhctnVpTUErFjqHWFBYDW40xTSLyaeAHQPNhnhOueemgmoAx5l5jzGTgP+3XPfiFRG4SkVIRKa2trR1ikT++1IQ43VtBKRVThhoK/wd0iMhc4D+A3cDDh3lOFVAccr8I2HeI8x8Drgz3gDHmfmNMiTGmJDc3d4hF/vjSEj3ap6CUiilDDQW/McZg9Qn81hjzWyD1MM9ZA0wVkYki4gWuB5aGniAiU0PuXgpsH2J5jglrbwWtKSilYsdQ+xRaReS7wP8DzrBHFsUd6gnGGL+I3AosA9zAg8aYMhG5Ayg1xiwFbhWR84EeoBH47NG+kUhIS/Bon4JSKqYMNRSuA27Emq9wQETGAXcd7knGmBeBFwccuz3k9tePoKzHXFpCHPuaOqNdDKWUOmaG1HxkjDkAPAqki8hlQJcx5nB9CqOe1aegzUdKqdgx1GUurgXeB64BrgVWi8inIlmwkUD3a1ZKxZqhNh99H1hojKkBEJFc4DXgqUgVbCRIS/DQ1RPA5w/g9ejagUqp499Qr3SuYCDY6o/guaNWcGtOrS0opWLFUGsKL4vIMuDv9v3rGNCBfDxKS7QXxevyk50SH+XSKKVU5A0pFIwx3xGRq4HTsGYq32+MeTqiJRsBUuO1pqCUii1DrSlgjPkH8I8IlmXEyUy2QmHt7kbmFGVEuTRKKRV5h+wXEJFWEWkJ86dVRFoO9dzjwdyiDM6YmsPPXtjM1gOt0S6OUkpF3CFDwRiTaoxJC/Mn1RiTdqwKGS0et4tfXD0Hf8Cwamd9tIujlFIRd9yPIPq4xqYnkJ4Yx9ZqrSkopY5/GgqHISKckJ+qzUdKqZigoTAEJ4yxQmHljjp6eg+34ZxSSo1eGgpDMG1MKm3dfm7842qeXXeoLSGUUmp001AYgplj+7aO2LTvuB90pZSKYRoKQzB/XCa/v/Ekpo9JpWzf4XYhVUqp0UtDYQhEhMvmFLBgfCab9rdgbUKnlFLHHw2FIzCrIJ3WLj+VDbrxjlLq+KShcARmF1rz9T7SJiSl1HFKQ+EITM1LRQS26UQ2pdRxSkPhCCR63YzPStJQUEodtzQUjtA0nd2slDqOaSgcoWn5qVTUd9Dt7412UZRSathpKByhaWNS6Q0Ydta2R7soSik17DQUjtC0/BQAtte0RbkkSik1/DQUjtCYtAQAalu7o1wSpZQafhoKRygtIQ63S2ho76Y3YHR2s1LquBLRUBCRJSKyVUTKReS2MI9/S0Q2icgGEXldRMZHsjzDweUSMpO87GnoZMGdrzLz9mW8W14X7WIppdSwiFgoiIgbuBe4GJgJ3CAiMwec9iFQYoyZAzwF/DJS5RlO2clePtjdSFNHD509vby2uTraRVJKqWERyZrCIqDcGLPTGOMDHgOuCD3BGPOGMabDvrsKKIpgeYZNVrKXvU3W+kcel1C2V5fTVkodHyIZCoVAZcj9KvvYYL4IvBTB8gybrBSvc/uCmfmU7WsmENC+BaXU6BfJUJAwx8JeOUXk00AJcNcgj98kIqUiUlpbWzuMRTw6OclWKHhcwlnTcmn39VJRr/MWlFKjXyRDoQooDrlfBBy0l6WInA98H7jcGBN2nKcx5n5jTIkxpiQ3NzcihT0SWcnxAOSnJTCnKAOAjXt15VSl1OgXyVBYA0wVkYki4gWuB5aGniAiJwF/wAqEmgiWZVgFm4/GpCcwOS8ZgD31HYd6ilJKjQoRCwVjjB+4FVgGbAaeMMaUicgdInK5fdpdQArwpIisE5Glg7zciJKd3BcK8R43GUlx1NiT2f73zXJdRVUpNWp5IvnixpgXgRcHHLs95Pb5kfz9kZJlh8JYe3Zzbko8ta3ddPp6+eXLW2ls9/H9SweOvlVKqZFPZzQfhdCaAkBeWjy1bd20dPUAsK+5K2plU0qpj0ND4ShMyEnmmgVFnD8jH7BqCjWtXbR02qHQpHs4K6VGp4g2Hx2v4twu7rpmrnM/Ly2B2tZumjUUlFKjnNYUhkFuSjxdPQFnlnNNazc9vYEol0oppY6chsIwyEuz5i3ssDfeMQYOaL+CUmoU0lAYBrkpdiiEbLyjTUhKqdFIQ2EY9NUU+kJhv9YUlFKjkIbCMMhNsYam7qxrx+2ylnyqatQZzkqp0UdHHw2DtEQPqfEeWrv95KbGkxDnomyfLqetlBp9tKYwDESE4qwkANISPCwYl8na3Y26VadSatTRUBgm44KhkBjH/PGZ1LR2O0NUlVJqtNBQGCbjsoM1hTjmj8sEYO3uxmgWSSmljpiGwjApDqkpTB+TSlayl7tf3dZvaOpdy7bw9IdV0SqiUkodlobCMBkX0qfgcbt44LMlVLd0ce8b5QAYY7j3jR188/H17G8+uFnpqbVVPPPh3mNaZqWUGkhDYZiE9ikAzB+XycIJWazd3cjXH/uQB9+tcM793zd2APD75dt57P09ANz31g4eWlmBUkpFk4bCMCnMSCQvNZ6peSnOsQXjM9lyoJVn1+3jj2/vdI5vsLfufLy0kuc37Kc3YNhT30F9W9jdSAFrZ7f3dzVE7g0opRQ6T2HYeD0uVn/vPETEORbscAY40GLNcF44IZNN+1owxtDQ5iMj0cv+5k58vQHq2roxxvR7jaB7lm/nza21lP5gVO5LpJQaJbSmMIwGXsznjctg4PX97BPyaPf1squunXZfL02dPirqrNnPXT0BOny9YV+7rq2burZuunrCP66UUsNBQyGC0hLi+MGlM/ncqRMASI33sGC8VXtYtdNqCmru6KGivt15Tn2bL+xrNXboXg1KqcjTUIiwL54+kU8tKAKgMDORafmpAKzaWQ9AS5efnbV9oVA7SL9CU4cVFrrQnlIqkjQUjoHJuSmIQFFmIlnJXnJSvE4oAGzc2+QspDdYZ3OTXVPQWdJKqUjSUDgGEr1uzp6Wy2lTcgCYkpdCTWvfxb9sXwszxlo1iPr2g5uPegOGli4rFPY3aU1BKRU5GgrHyEOfX8TnT5sIwNS81H6Pdfh6ObEwA4C61oNrCs2dPQTX1tM+BaVUJOmQ1CiYlp9y0LGJOUmkJngOqilU1LXzwZ6+NZT2hZkNrZRSw0VDIQqmDKgpABRkJJKbEk/dgD6F7z+zkXfLrf6HJK/7qDuae3oDrNhey7nT84/q+Uqp2KDNR1Ew1a4pjE1PcI4VZCSSneKlNqT5qK3b328W87T8VKpbji4Ufv3KNr7w51KdFa2UOiQNhSjISYknK9nLxJxk51hhRiJj0hOdmc8AK8vr6Ont26hnUm4yrV1+enoDR/w7N1Q1AYSd/Nba1cNND5dS2aBbiCoV6yIaCiKyRES2iki5iNwW5vEzReQDEfGLyKciWZaR5tsXTuMLp00kMc5NnFvITYmnICOB/c1dBAJWECzfUoPX3fcRTc61ahiNHeEnuB1Kc6c1eikQZje4D/Y08cqmam5+ZO3RvBWl1HEkYn0KIuIG7gUuAKqANSKy1BizKeS0PcDngH+PVDlGqn85eTwA6YlxxHkEl0sozEjE5w/w55UVNHb4eGbdXq6YV8CTa609GMbbG/k0tPvIS00Y9LXDCQ5pbe8+uKYQrD1s2t+CvzeAx60VSKViVST/9y8Cyo0xO40xPuAx4IrQE4wxFcaYDcCRt4ccJzKS4ihITwRgrP3zjuc38bvl5XT1BLj5rEnOuVnJXsAKhaBAwNDe7Qes9ZGWrt8X9ve0dFrnBM8N1WxPjIO+5TeUUrEpkqOPCoHKkPtVwMlH80IichNwE8C4ceM+fslGkO9eMoMkrxuAgoz+3/6/fPZkpuSl8vOrTqS8ps0Jhcb2HlZsr+X1zTXkpsbz4Du7WPW983hgxS7ue2sHiydlk5sa3++1gs1HbWFCoamzL2R21LZx+tScYX2PSqnRI5KhcPD6z3Bwg/YQGGPuB+4HKCkpOarXGKnOmpbr3C7MSHRu//b6eVwxrxCA6xdZQVjTanVCN3T4eLy0kre31ZKa4KHVXj+ptML6lr+rrr1fKHT4/GFvBzV19OB2CR6XUNWonc0K1lQ0kJsSz4SQwRAqNkSy+agKKA65XwSEb9tQgNW/EKw1zCpIP+jxzCSrprC/qZPV9tpJrV3WRX5dZaOzec+uujaaOnw8WVqJMYZ9IUtjtIXpU2jq7CEzKY6izESqGnVynIJvP7Ge3y0vj3YxVBREsqawBpgqIhOBvcD1wI0R/H2jnohQkJFIVWNHv+GqQXFuF2kJHl4uO0C3P0BxViL7m7pwifBEaRU+v9U1s6uug4fereC3r28nPy2h354Og/UppCfGUZSZpKGgAGuYcmtXz+FPVMediNUUjDF+4FZgGbAZeMIYUyYid4jI5QAislBEqoBrgD+ISFmkyjNanDAmlZLxWc6qqQNlJXvZWduO1+3i8ZsW8/jNi5k+NpW1u62lMHJSvOyqa+Pt7bUA/GVlBZUN1oXeJX2hsKe+gx8vLWPz/haaOn1kJHkpykykckDzUaevl2vve4/3dtRzJO54bhOPrNp9RM9RI0dnTy+duqFTTIroMhfGmBeBFwccuz3k9hqsZiVl+9Wn5oadSxCUmeylor6DU6dkU5CRSEFGIjkpVv/BDYuKqW31sa6yidrWbrKSvSzfWkNKgod4j4vx2Um0dfupqGvnk//7Lo0dPfx11W7cLuH0KTkUZSbR1GF9Q0xNiANgxfZa3q9o4J8fVLF4cvaQ38dzG/YxuyCN/3fK+I/3F3KM7KnvYGxGAnE6HJdAwNDVEwhbq1THP/0fMMIket0kxw+e1cG1kS6cOcY59qUzJnLZnLHcftksJuUmU93STcDALWdNwhh4payaiTnJpMR7aPf5ufvVbXT7Azz0uYX4A4Zuf4B0u08B+u/Z8NrmagBW7qjHhAmrP769s9+CfWBdVBrafTR1Rr/5oanDx82PlPZbPmSglq4ezv/NWzz94d5jWLKD9fQGDlnOY6XLb9UQBtsaVg2f7dWtzP7RshG1moCGwijT1G5daM+fmeccO3VyDr+/cT6JXjdnTs1lQnYSnz9tAtcvGoeI1RQwMSeZ5HgPH+1t4bkN+/jM4gmcfUIuqQlWAGUkep1QCO4ZHQgYlm+pISHOxd6mTvYM+Ifb2tXDz17czJ3Pb+p3vKWrh96AcTYGiqYP9jSyrKya1bsGb/6qbe3G5w+wN8r9KX9/fw/n/vpNp28oWoJhoM1Hkbejts2qvYdsyRttGgqjzEOfX8gPLp0x6Izm06fm8OZ3zuFHn5hFWkIcE7KtDutJuVZNIbg3wzUlRYgIU/KspTMykuKYMTaNlHgPb2ypAWBXfTt1bT4+a+8x/d6OerZVt9JpXzQ+2tsCWMtkbDnQ4pShzt5nuukoluMYbjUt1jfvQ21OFAyv5ijXbPbUd9Da5e83OTEagp9vuNnvseYnz5Xxtb9/GLHXD44ebOsaOU11GgqjTMmELL50xqTDn2ibWZAGwMScFKdZSgSKM60lM4IrtaYnxpEQ5+bCmfm89NF+fP4A5TVtACyZNYYkr5vS3Y1cds87/HllBWBtIwrgcUm/ppfglqLNnT3OOk7REmyOOdQ2psHwinaINdrhNHD59GMtuOxJZ5g5LbFmfWUTZfuaI/b6wcmkrSOo/0ZD4Tg3c6wVCpNyk0kOzpxOT8TrsT76MWlWk1G7fQH4xNwCWrr8vPTRficUpuSlMDk3hVc3VePrDbCz1jq+oaqZwoxEJuemsMM+F/qW4QiYvm9Cx8qO2jau/cN7zgU+uO1puB3r3ttRT7e/16kpRLsPpNmeWR5uS9ZjKdh81NHTG7YfKZbUt/vCrgIwXNq0pqCOtcvnFnBtSRGzCtKcmkKw7wDg/BlW38SMMVZ4nDE1h9mFafzkuU28v6uB/LR4UhPimJyb7DSvBIetbtzbzJyidMZlJ7G7voOtB1q55ZG1PPDOLuf1j2ZFVwBjzFFdkILlDg6hDc4CH7hj3brKJm744yp++9p2p4zR7gMJ/v76KNcUgn0JxkBXz/G9LNl9b+3gxY37B328oc0X0Qt2m/1lLJLBc6Q0FI5zxVlJ/PJTc4n39I1qyk/r6484dUoOa75/PudMt8LB43Zx97XzaO7s4a1ttU6fQ3DZboCqxk6qW7rYXd/BvOIMxmclsaehg88++D4vlx1w5kxA+G/flQ0d7Ko7uGNtfWUTz9jNUD9aWkbJna/1e7y8po3fvb6dVzdVc+p/v+60fQNOgOyxO+x89p4TfTWF/n0KwSaB/c1dTthFu08h+HdV3zYy+hQg/LIox5M/vbOLf34QftRZt7+X1m4/7b5eeiPUDOrUFDQUVDR47AlxwYX1ggYunjctP5WLZlnbdgbXYwqGA1gX0re2WpPjTp+aw/jsJLr9AQ60dDnNUkEDawq9AcNnH3qfa+5776D/CP/35g6+9/RG/L0BHn5vN/XtPvY2dbLGXtPpynvf5devbuPljw6wr7mLvU1WjWX5lmrm/OQValu7nRFSwQ7mYJ9CQ7uv38Vu24FWAFITPCE1hehejIM1hbr2kVFTgON7WGpvwFDf1u002w0U2uHfHqFwdPoUtPlIRUOwIzN7QCiEE9zvocjukJ5sh0JCnIvegOHJtZVkJ3uZMSaNcdl9S3J8dnH/yWrfeXI9v1++3bn/4sb97Kxtp66tm/ve3NHv3B21bXT4enmitMo5dufzm7j+/lU0dfS17QaHlwb3q37wnQpau/w8v2EfwS90tW3dGGOoae0mzw69/SFNSMF1ourbff1GH0WrY9wY44RSQ5RrCh2+2AiFhnYfATN4s2FojS1STUhaU1BRlZFkzVIO/dY/mNOm5PDEzYu56UxrpNOE7GROyE/l2hJrjcM1FY2cNiUHl0sYl2UFR0q8h6sX9J+gXtfm457l5Tz8XgWvb67mD2/vYHJuMhfNyufR1bvx9wbYUNXEq5uqnbHa97zeFyKrdzXQGzDc//ZO51hwfaYDzV1UNnTwTnkdQL8RULWt3bR0+vH5A8wrzgBwmqx6egNs2mcNoa1r7XYuCgETvVEg7b5e/HYgRbujuX9NYeRcrIZbsL9psAEGoZ9DpC7awddtG0HrTEV0mQs1snzx9IlMyE52moYOZ9HELOe21+Ni2TfPZHd9Ow+/Z61pdN1CKyAKMxJxCcwtTmdqXupBr+PzB7j92TK8bhe+3gA/vXI2uSnxLCur5o2ttfzwmY+oae1yvuUfaOliWn4K26rbnCp8aOd10IHmLp5aW4WI1TS2oaqZJK+bafmpVLd08fSHVo3j/Jn5vFtexytl1Zw3I5+nP9hLtz1BrK6tm0R7VBZYiwN6XEJinBvXIOtPfbS3md6AYU5ROiLhzzlSoU1Xw9nRXNnQYX0+9nsxxnD3q9u4bE4BJ4w5+LMC6AqpHXQexzWFYNNic0cPxpiDPsuGkGa8SDXvOKGgNQUVDXFuF0tmj/lYF7ICu49hbnEGp02xNuPxelxcv2gc1y0ch9sl3PWpOTwogIDpAAAa2klEQVR20ynOc65fWMxV8wsJGEOS182V8wo4a1ouiXFuvv3EOg609AVC0NXz+9c4fP4AXzhtYr+mr33NnTy1torTp+Q4HeHTx6SSnxbPyh31/Pg5a6b1tPxULpw1hpfLDlDT0sUdz2/i5IlZ/MvJ46hr89HY3kOaPbP7W0+sY9aPlvHoaiv4jDFs3t/i/Kf19wa4/v5VXHHvu/zw2Y+csgx1pNQrZQf4zavbDjoerK2kxHucyX9Hwt8b4C8rK5w5BgCb9rVw1l1v8JA9rwSsJpPfLS/n7+/vGfS1jkXzUW/AON/Uj0bXUcy2vvVvH/Dsuv61SbAGJYSbvd2v+SjCNQXtU1CjVpzbxTv/eQ5P3bK43/H/+uSJXD63AIBrSoo5ZVLf4nk/v3oOd187j9s/MZPvXzqD1IQ4Er1uLp9bgAFuPWeK00E9p8jaR+Li2WOdvSVmjE1jal4K37hgKkV2UxXAPz7Yy96mTq5bWOzM3J4xNs2Z7R3vcfH8V09nblE6l80ZS3NnD3e/uo22bj//sWQ6eakJNHf2UNvW7SxVXmqPnFq9qwFjDP/ywGou/u0Kfm/vLfBhZRNt3X7SE+P466o9PLp6N+f+6k1+vHRoC/ze9Mhafvv69oNCJBgKk3OTqW/vPuLhuCvK6/jR0jLnovfWtlrueX07AQMPrNhJjz0a60CLdSE+1ISs0AvkYB2sP3hmI996Yh0A1S1dYUeTHcrf3t/Dmb98o99WsENV1djB9B++zJOllYc/2dYbMLywcT/vbK9zjtWErDMVrl+hX/OR9ikoNbiizKQhrSb6uxtO4tEv9e3A+pnFE5wObICfX30i62+/kH+/6AROnZxNXmo8V8wr5NTJ2YzLTmKMPXT2q+dO4dVvnUVaQhzF9hyL1AQPPn+A1HgPF8zMd3YIm1mQ5oymml2YzuxCq4nntCk5xHtcPLW2Cq/HxYmF6eSkWrUOnz/A+JDO8pMnZrGtupXN+1tZac932F7dSofPz8sfHcDtEl7+xhmMTU/g+09/xM66dv66uu+b92AX9NBd7QZehIJbos4Ym0ZXT4CK+g4ONHfxwIqdQxoOub7Sml2+emcD26tbneHBswrS2N/cxUsfHQD6RmWV7Ws5qFPdGMMdz23i+Q19e2EN1nz0+uYa3t5mjUC77R8buOWRtc5je+o7Dlpq/dl1e7nuD+85v3PFtlq6egJsDlkeZah21loBdOcLm4f8nIZ2H8b0Hw1Xe7hQaOsm2ILY1n10bf5vbavlkt+uGPTvUZuPVEz5xNwCp4kpHBFx2rrvvHI2f/xMCV88fSJ/+1er6Sk4nyJ0sl2xXVOYW2R1Hp87I494j5tJuXYojE0j3q51TAmZW5EQ52bRxCz8AcPconS8Hpez5Dj0n4dRMiGTHbXtLCuzLqTzijOobOzg0nve4U/v7GLB+EzGpify0tfP4PGbTuFr506hN2DY29TJZx58n28+vq7f+9zf3EllQwevbqp2jg2cTBe8KH36lPHEuYW/rKzgnuXbufOFzTy+5vDfiDdWWd/8V+2sZ3e9FT4XzMznL19YRF5qPC/ZE7Sq7ZpCh6+XXfXt/OjZj1i5w/r2/OjqPTz47i6qGjtJjLNqabf9cyMPrNjZ73c1tvvY39xFXZuPurZuVu9qYFddu3PB/81r2/jK3z7o95yH39vN6l0NVNS3Y4xxamRb9h95KNSFLKMy1GHEwecE+6ieWlvVb9JaU5hhqQ3tPsamW//2jrZ558/v7mLT/hY2hXmfPn+Abn8AEavGMFJmj2tHsxoRijKTnOGvQWPSE5zHgpbMGkN1c5czYuRce9LdJ+YU4HEJ84oznNFJwQl5QWdOzWXF9jrmj8sE6BcK/3LKOFq6erimpIht1W30BgwPrNjJ7MI0FozP5M8rK+gNGDwu4VsXTAMgI8nLyZOy8biFe5aXc+1977G3qRMRq3M7Od7Dh7sb+d83d5CeGNdvfsi+pq5+W64GL1ZT81P4xNwCniitdDY5/9UrW7n0xLGkJ8XR2O5j+ZYaPnlSYb/O4/VVzcR7XOxr7nKG7P7sytnkpMRzwcx8nv5wL109vU7zEcCrm6r5y3u7aenyc8rEbH71ylbnsaxkr7Ne1MsfHei33tbmkAvcs+v2Of0ONa3djElPYHtNKw3tPrp6elm9q4G/rKxwJjRuqGomYPre79bqVgZ6t7yOe17fzu9uPCnswo/VLX3f8F/ZVO2MiDuUYP9Ao92p/O9Pru/3eLAZ693yOuLcLhZNzGJfUxdT8lLY29R5VN/kG9t9rLCbq7YeaGVecUa/zbOC+1XkpsRT09pNtz9AQpw77GsdS1pTUCPWrII0xmUlkWkPpQWrg/vu6+bx9fOmct70PGdfiUSvm6vmWyu/XjZnLC99/QyWzB7T7/XOm5GH1+3irGm5AOSnWaEwtyidnJR4fnjZTKaPSWO6PSqn3dfLklljGJeV5DThPPyFRf36S6xyWhf3vU2dXHLiGIyBW//2IZ9/aA33LC/n9Kk51Lf72F7Txm0XTwfgb6t38+OlZXT4/Oyp72Dt7kYm5SYT73Hz7QtPIDPJS7uvl59eMYumDh//8/o2Wrp6OPfXb/LtJ9fzTnkdWw+0UnLnq6zYXkddW7czHPj5DfuJc4sTehfOGkOHr5c3ttRQ3dJNRlIciXFuHrRHdJXta2Z7TRtN9rasgPMToKK+/5Lpod96/7a6b3e9Hy8t4+uPfeg071S3WM1fy+1Vd10C66uanFV4C9IT2Ly/fyjsrm/n5kfWsnpXA/9YG36mcU1rF8leN/lp8c4kSoAtB1poCRnaGQgYLvrN21xz30o22Is3NrT7+gVj8O8o+CXjp89v4qf2UvCVjR2Mz04i2es+bJ/Crrp2Z7Rb0CubDuAPGFwCf1yxkzk/XtZvZFkwaIJffmpbu7nn9e1Rb0rSmoIasb54+kQ+f9rEsKOl5hZn8KfPLQz7PBFhhr0QYKhJuSms/9GFzhDUoswk7r1xPmdO69/ENTEnmcykOGYXpnPzWZNZsb3vwhPudRPi3BRnJVLZ0Mnd186jw7eWirp2lsweS8AYblsynVv+upYtB1r5/GkT+PUrW3ljay1Qywsb99NiX5BuWDQOsIb4PvVviymtaOSyOWPZcqCVh9/bze76DmcC4rs76khLiKOuzcd3/7nRev7CcTxZWsn+5i6Ks/qGoS6elM2knGR+/FwZBRmJFGYkMiE7mRfs5pPymjZnrsdV8wt56N2KfvMT6tq6ae/2O8ukbNrfQk5KPM2dPnbUtpPkddPh6+Vlu7kt6EBzl9Nc9aXTJ7KusomH3q3A63Zx6uRspuWn8viaSnoDxvkG/fb2Otq6/YzPTuLpD6u45axJB33+NS3d5KcnUDI+k5c/OoC/15pNv+R/VgDwxM2LWVPRwNyiDKcmsr7Sal5r7uxhiz2b/ZvnT+Oi2fks+Z8VNNk1iKrGTnp6AzS0+2jt8lOcmURKguewF+r73tzB46WVdPoCPLtuL49+6WTe21FPbmo8RZmJfLjHCqUP9zRx/kxrSLgTCmkJbKCZJ0or+d3ycnJT451/CyvL6/jFy1v42SdPZHZhevhfPsy0pqBGLBEZdK/qoxU6JwHg0jljna1Hg+LcLt777nk8/IVFxLldzuS8MWkJZA4yG/yZL5/GutsvICHOzX2fXsCr3zqL2y6ezvcumYHLJdxzw0k8/7XTife4yUzy2u/PuuAGd78LDaex6Yl8Ym4BIsJ3LjqBnBQvy7fUcP3CYhZNzGJleT3v77KW/9jb1Mn0ManMLkxz+kYK0vv6YbweF7+78STq2nx8uKeJ/LQEpxbldbsIGHh09W5yUrycOdWqRdUM2AEu2E/R1OHj1U3VnDwpi55eq/b00ytmh/07qWzsZGdtO18+ezI/uGwmc+x+oEm5ydx743xOmZRNZ08vD73bNweloq6dhDgXXzpjEtuq25yLeiBgWFZ2gN8v387OunbyUxM4a1oeLV1+1u5u7Deq6L9f2sxdy7byy2VbnGPBtbAAPrCbsm5YVMwJ+al4PS6aOn20dPpp6/bT7Q84XwSKsxJJiffQ0tXDvW+U8z+v9Q0ntlbYtZql1ldZF/07X9jE6l0NfFjZxPu7Glg0IYvpY/q+SGzc2zfqKxgKweXrn1pr1TSCgxv2NXVy4wOrWV/VzFvb+r6YRJqGglJhJMS5nW+owT6N6WPDT/YCyE6JJ8O+2CfEuQ8anZUQ5ybNDp/gBffua+fyzJdP46qTCkmIc3HyxPB7YGckefnNtfNYNCGLb14wjdMm57Bxr3WhCM6vuGp+ISLiTEgLrlkVNKsgnQtm5NuvF8c50/NITfDwqRKryWlnbTsLxmcyPtt6rx2+XjKS4pyd+Srq27nvrR18+k+raev289Vzp/CLq0/kG+dP5eoFRc5SIqFW7qjDHzBOmb5yzmTuvXE+z331dDKTvVw0K5/zZ+Tzy2VbeWHDfk75r9f5YE8jE7KTnbIGL/a/eW0bNz+yll+9so3N+1vIT4vnjGk5ZCbFcecLm3ljaw35afFcODPf+Va+we58P2VSVr9yraloIDXBQ25qPCJCRmIczR09zuq/YPVVgPXZpyTE8eLGA9y1bCv/89p2Z3jvr5Zt5YLfvE1Du49tdngF+1f+umo3+5q7WDQxy57kaDXJBYcCd/j8ziz9eeOssAwu2/Lejrp+nfFgheVTa6sOuS/IcNHmI6UOIyHOzXnT87hg5tBmgh9OsLnlwpljSI73MC0/lVvOnnzIvblPnZLDqfZIrktOHMNv7G+s/7FkOjtq27iuxGpumJZvXYALBoQCWDPQXy47QFuXn5R4D2995xxSEzxsqGqiqyfAzWdN7tep/+EPL6Cly8/cn7zCz1/awp6GDoqzErnpjEl230vfN+DirCRq27qZXZDOzto2DDhDVoPnZafEc+mcsc5zRISvnDOZ1zZX85Pnyqhp7eZASxcXzcpnTHoCk3KTebfcaib73fJyri0pYuWOeqoaO8lLSyAtIY7/vmoOt/x1LRv3NnPVSYXMKUp3LuhgzXQ/+4Q8Vu1scI6tqWjkxMK+2eg5KfFUNXb2u+AGR4oVZyax0a4F5KbGU9vazdYDrcwuTGfF9jpqW7u5a9kWAgaSvW7afb2kJ8bx7DprWO/CCVlMzU9hwfhM/veNcp5Zt49vPb6OwsxEXt1UzXcuOoEr5xXS3t3LL1/ewidPKuQv7+3mkVVWc2G8x8XMgjTeKa/jybVV3HnlbD59Sv/1xYabhoJSQzBY/8XRePKWxWyrbnVCINHr7jck9nCm5qdaw2HXVHLlSYWkhIRJsJN8bMbBo3bOmpbLV8+dwpUnFQJ9q+U+/9Uz+p3ndbu4eoHVaZ+eGEdOipc9DR18ZvF4fnL5rLB9PPPHWSNrvnPRCeyqa+e+N3ews66dOLc4w4XDObEwndR4T7/mquBExFMnZ/PXVXt4Y2stZ07L5adXzuY7T26gqrHT6QhfMnsMv75mLr9+ZSufnF/ojFbyelz4/AEKMxOdfqD8tHiqW7rpDZh+638tnpzNI6t2s3hydr/zvB4X6UlxfOmMSbxSdoAHPlvC+Xe/zYaqZsZnJzlNW39/3xoy/LXzpvLPD/Zy3cJi7nh+E1edVMj0Mam4XMK0/FRmF6bzzLp9/NNeo+ukcRl85ZwpgDUU+cZF42ju7OG9nfXc/mwZcW5hdmE6U/NSnNrPgvGZg/5dDhcNBaWOsVkF6f2Gox6NGWPT+PHlsw46XjI+i8WTsjl18sHzQ1wu4dsXnnDY1972s4v73b9yXiEi8N2LZwy6RMr3L53prB+0cEIWf11ljUo6b3r+ISc6etwuTp6UzWub+77dBycinj0tj7+u2sNpU7L5w6cXEO9xs3hyNkvX78Mb8ppXLyhyRl4ZY/j2BdNI9Lq584XNjMtKYlq+FQBT81Kd4axnTO37+znnhDz+9M4uniytJMnr5nuXzODrj63DZ6+P9b1LZvBde9RYRlIc6yubKM5KxBj41IIiyva1sGhCJjefNZmbz5qMMYYbFo07qP/quoXFuF3Cyh31vLqpmmsW9B9K63IJmcleln3jTK79w3usqWhkTmE6+XafQ4pdq4w0DQWljiPpSXH8PWTdqeHwg8tmDum80MAIzpy+5ezJh33eWdNyeG1zNUvs9amC/Rrnzcjj+a+ezsyxac5IqmtLinGLcPm8gkHL8NXzplLZ0MGdL2xmQnYyY9ISmJKXwhlTc5xRVmef0DeHZeHETJK8birqrcUDr5hXiMfl6rc3SPC9zSnK4O3ttbT7/LgEfvSJmQcNVBCRgwIBIDUhjs+fNpHzZ+STk+LlikO8hy+fM4XPP7SG+eMznQA8aVzGsA+8CEdDQSk17O6+bi5rKxqdZcsP5fpF45hXnImINTcgWIsSkYOGYbpdwrULDz9ZrTAjkSWzxnDBzHxEhNe+dRYA//2SNSIpdB5GvMfNN8+fxs9e3Ox0+ob2fYT6ytmT+dLDpTy/YT+fPmXcQYEwFMVZSfz3VXMOec45J+Tx9JdPZU5RhtOJHZx0GWkyUqZWD1VJSYkpLS2NdjGUUqPQP9ZWccKY1LBj/hvafXg9rn59NOFUNVrrUpVMyDrkecOlN2D41Stb+fQp4w8aVXYkRGStMabksOdFMhREZAnwW8ANPGCM+fmAx+OBh4EFQD1wnTGm4lCvqaGglFJHbqihELF5CiLiBu4FLgZmAjeIyMDGyS8CjcaYKcBvgF9EqjxKKaUOL5KT1xYB5caYncYYH/AYcMWAc64A/mLffgo4T4ZrKyullFJHLJKhUAiErvlbZR8Le44xxg80A+GndSqllIq4SIZCuG/8AzswhnIOInKTiJSKSGlt7bFbA0QppWJNJEOhCggdO1YE7BvsHBHxAOlAw4BzMMbcb4wpMcaU5ObmRqi4SimlIhkKa4CpIjJRRLzA9cDSAecsBT5r3/4UsNyMtjGySil1HInY5DVjjF9EbgWWYQ1JfdAYUyYidwClxpilwJ+AR0SkHKuGcH2kyqOUUurwIjqj2RjzIvDigGO3h9zuAq6JZBmUUkoN3aib0SwitcDuw54YXg5Qd9izRgd9LyOTvpeRSd8LjDfGHLZTdtSFwschIqVDmdE3Guh7GZn0vYxM+l6GTndeU0op5dBQUEop5Yi1ULg/2gUYRvpeRiZ9LyOTvpchiqk+BaWUUocWazUFpZRShxAzoSAiS0Rkq4iUi8ht0S7PkRKRChHZKCLrRKTUPpYlIq+KyHb757HZmukIiciDIlIjIh+FHAtbdrHcY39OG0RkfvRKfrBB3suPRWSv/dmsE5FLQh77rv1etorIRdEp9cFEpFhE3hCRzSJSJiJft4+Pus/lEO9lNH4uCSLyvoist9/LT+zjE0Vktf25PG6vEoGIxNv3y+3HJ3zsQhhjjvs/WDOqdwCTAC+wHpgZ7XId4XuoAHIGHPslcJt9+zbgF9Eu5yBlPxOYD3x0uLIDlwAvYS2WeAqwOtrlH8J7+THw72HOnWn/W4sHJtr/Bt3Rfg922cYC8+3bqcA2u7yj7nM5xHsZjZ+LACn27Thgtf33/QRwvX38PuDf7NtfBu6zb18PPP5xyxArNYWh7O0wGoXuR/EX4MoolmVQxpi3OXihw8HKfgXwsLGsAjJEJPyGuVEwyHsZzBXAY8aYbmPMLqAc699i1Blj9htjPrBvtwKbsZayH3WfyyHey2BG8udijDFt9t04+48BzsXacwYO/lyGdU+aWAmFoeztMNIZ4BURWSsiN9nH8o0x+8H6jwHkRa10R26wso/Wz+pWu1nlwZBmvFHxXuwmh5OwvpWO6s9lwHuBUfi5iIhbRNYBNcCrWDWZJmPtOQP9yzvse9LESigMad+GEe40Y8x8rO1NvyIiZ0a7QBEyGj+r/wMmA/OA/cCv7eMj/r2ISArwD+AbxpiWQ50a5thIfy+j8nMxxvQaY+ZhbTewCJgR7jT757C/l1gJhaHs7TCiGWP22T9rgKex/rFUB6vw9s+a6JXwiA1W9lH3WRljqu3/yAHgj/Q1RYzo9yIicVgX0UeNMf+0D4/KzyXcexmtn0uQMaYJeBOrTyFDrD1noH95h7QnzZGIlVAYyt4OI5aIJItIavA2cCHwEf33o/gs8Gx0SnhUBiv7UuAz9miXU4DmYHPGSDWgbf2TWJ8NWO/lenuEyERgKvD+sS5fOHa785+AzcaYu0MeGnWfy2DvZZR+LrkikmHfTgTOx+ojeQNrzxk4+HMZ3j1pot3bfqz+YI2e2IbVPvf9aJfnCMs+CWu0xHqgLFh+rLbD14Ht9s+saJd1kPL/Hav63oP1zeaLg5Udqzp8r/05bQRKol3+IbyXR+yybrD/k44NOf/79nvZClwc7fKHlOt0rGaGDcA6+88lo/FzOcR7GY2fyxzgQ7vMHwG328cnYQVXOfAkEG8fT7Dvl9uPT/q4ZdAZzUoppRyx0nyklFJqCDQUlFJKOTQUlFJKOTQUlFJKOTQUlFJKOTQUVMwSkZX2zwkicuMwv/b3wv0upUY6HZKqYp6InI21muZlR/ActzGm9xCPtxljUoajfEodS1pTUDFLRIKrUf4cOMNec/+b9oJkd4nIGnsxtZvt88+21+3/G9akKETkGXuRwrLgQoUi8nMg0X69R0N/lz0j+C4R+Uis/TGuC3ntN0XkKRHZIiKPftzVLpU6Gp7Dn6LUce82QmoK9sW92RizUETigXdF5BX73EXAbGMtuQzwBWNMg70kwRoR+Ycx5jYRudVYi5oNdBXWAm1zgRz7OW/bj50EzMJa1+Zd4DTgneF/u0oNTmsKSh3sQqx1ftZhLcGcjbU+DsD7IYEA8DURWQ+swlqYbCqHdjrwd2Mt1FYNvAUsDHntKmMt4LYOmDAs70apI6A1BaUOJsBXjTHL+h20+h7aB9w/H1hsjOkQkTex1qI53GsPpjvkdi/6/1NFgdYUlIJWrG0cg5YB/2Yvx4yITLNXpx0oHWi0A2E61hLHQT3B5w/wNnCd3W+Ri7W954hYoVMp0G8iSoG1IqXfbgb6M/BbrKabD+zO3lrCb3X6MnCLiGzAWm1zVchj9wMbROQDY8y/hBx/GliMteKtAf7DGHPADhWlok6HpCqllHJo85FSSimHhoJSSimHhoJSSimHhoJSSimHhoJSSimHhoJSSimHhoJSSimHhoJSSinH/weVcDXl7tnysAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample : 110; Expected Label: tensor([1]); Obtained Label: tensor([0])\n",
      "Sample : 228; Expected Label: tensor([1]); Obtained Label: tensor([0])\n",
      "Sample : 634; Expected Label: tensor([1]); Obtained Label: tensor([0])\n",
      "Sample : 748; Expected Label: tensor([1]); Obtained Label: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "            count = 0\n",
    "max_num_of_items = 4  # first four mis-classified samples\n",
    "validation_loader_batch_one = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)\n",
    "\n",
    "for i, (x_test, y_test) in enumerate(validation_loader_batch_one):\n",
    "    # set model to eval\n",
    "    model.eval()\n",
    "    \n",
    "    # make a prediction\n",
    "    z = model(x_test)\n",
    "    \n",
    "    # find max\n",
    "    _, yhat = torch.max(z.data, 1)\n",
    "    \n",
    "    # print mis-classified samples\n",
    "    if yhat != y_test:\n",
    "        print(\"Sample : {}; Expected Label: {}; Obtained Label: {}\".format(str(i), str(y_test), str(yhat)))\n",
    "        count += 1\n",
    "        if count >= max_num_of_items:\n",
    "                        break\n",
    "    # end if\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html\"> CLICK HERE </a> Click here to see how to share your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
