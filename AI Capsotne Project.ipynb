{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a href=\"http://cocl.us/pytorch_link_top\">\n    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n</a> "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1><h1>Pre-trained-Models with PyTorch </h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n<ul>\n<li>change the output layer</li>\n<li> train the model</li> \n<li>  identify  several  misclassified samples</li> \n </ul>\nYou will take several screenshots of your work and share your notebook. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Table of Contents</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n\n<ul>\n    <li><a href=\"#download_data\"> Download Data</a></li>\n    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n    <li><a href=\"#data_class\"> Dataset Class</a></li>\n    <li><a href=\"#Question_1\">Question 1</a></li>\n    <li><a href=\"#Question_2\">Question 2</a></li>\n    <li><a href=\"#Question_3\">Question 3</a></li>\n</ul>\n<p>Estimated Time Needed: <strong>120 min</strong></p>\n </div>\n<hr>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"download_data\">Download Data</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-04-24 10:36:26--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2598656062 (2.4G) [application/zip]\nSaving to: \u2018Positive_tensors.zip\u2019\n\n100%[====================================>] 2,598,656,062 45.0MB/s   in 59s    \n\n2020-04-24 10:37:25 (42.1 MB/s) - \u2018Positive_tensors.zip\u2019 saved [2598656062/2598656062]\n\n"
                }
            ],
            "source": "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "!unzip -q Positive_tensors.zip "
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-04-24 10:39:51--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2111408108 (2.0G) [application/zip]\nSaving to: \u2018Negative_tensors.zip\u2019\n\n100%[====================================>] 2,111,408,108 45.1MB/s   in 44s    \n\n2020-04-24 10:40:35 (45.7 MB/s) - \u2018Negative_tensors.zip\u2019 saved [2111408108/2111408108]\n\n"
                }
            ],
            "source": "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n!unzip -q Negative_tensors.zip"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We will install torchvision:"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting torchvision\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/51/aa2770a70f612ce9a2fc7da3a1a93f9ecf8746788256fed6b691f9b31ca9/torchvision-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.6MB 9.2MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (5.4.1)\nCollecting torch==1.5.0 (from torchvision)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/70/54e9fb010fe1547bc4774716f11ececb81ae5b306c05f090f4461ee13205/torch-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (752.0MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 752.0MB 19kB/s s eta 0:00:010MB 42.9MB/s eta 0:00:17:00:06MB/s eta 0:00:03\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (1.15.4)\nRequirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch==1.5.0->torchvision) (0.17.1)\nInstalling collected packages: torch, torchvision\nSuccessfully installed torch-1.5.0 torchvision-0.6.0\n"
                }
            ],
            "source": "!pip install torchvision"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "<torch._C.Generator at 0x7fd3fc08b6b0>"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# These are the libraries will be used for this lab.\nimport torchvision.models as models\nfrom PIL import Image\nimport pandas\nfrom torchvision import transforms\nimport torch.nn as nn\nimport time\nimport torch \nimport matplotlib.pylab as plt\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport h5py\nimport os\nimport glob\ntorch.manual_seed(0)"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "from matplotlib.pyplot import imshow\nimport matplotlib.pylab as plt\nfrom PIL import Image\nimport pandas as pd\nimport os"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"data_class\">Dataset Class</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step."
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "done\n"
                }
            ],
            "source": "# Create your own dataset object\n\nclass Dataset(Dataset):\n\n    # Constructor\n    def __init__(self,transform=None,train=True):\n        directory=\"/home/dsxuser/work\"\n        positive=\"Positive_tensors\"\n        negative='Negative_tensors'\n\n        positive_file_path=os.path.join(directory,positive)\n        negative_file_path=os.path.join(directory,negative)\n        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n        number_of_samples=len(positive_files)+len(negative_files)\n        self.all_files=[None]*number_of_samples\n        self.all_files[::2]=positive_files\n        self.all_files[1::2]=negative_files \n        # The transform is goint to be used on image\n        self.transform = transform\n        #torch.LongTensor\n        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n        self.Y[::2]=1\n        self.Y[1::2]=0\n        \n        if train:\n            self.all_files=self.all_files[0:30000]\n            self.Y=self.Y[0:30000]\n            self.len=len(self.all_files)\n        else:\n            self.all_files=self.all_files[30000:]\n            self.Y=self.Y[30000:]\n            self.len=len(self.all_files)     \n       \n    # Get the length\n    def __len__(self):\n        return self.len\n    \n    # Getter\n    def __getitem__(self, idx):\n               \n        image=torch.load(self.all_files[idx])\n        y=self.Y[idx]\n                  \n        # If there is any transform method, apply it onto the image\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y\n    \nprint(\"done\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We create two dataset objects, one for the training data and one for the validation data."
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "done\n"
                }
            ],
            "source": "train_dataset = Dataset(train=True)\nvalidation_dataset = Dataset(train=False)\nprint(\"done\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Question_1\">Question 1</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Prepare a pre-trained resnet18 model :</b>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/dsxuser/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7b6b712a81b7462fb711447959a7a186",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": "HBox(children=(IntProgress(value=0, max=46827520), HTML(value='')))"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\n"
                }
            ],
            "source": "# Step 1: Load the pre-trained model resnet18\n\nimport torchvision.models as models\nmodel = models.resnet18(pretrained=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training."
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "# Step 2: Set the parameter cannot be trained for the pre-trained model\n\n\nfor param in model.parameters():\n    param.requires_grad = False"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": "d_hidden = 512\nd_out = 2\n\nmodel.fc = nn.Linear(d_hidden, d_out)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n"
                }
            ],
            "source": "print(model)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Question_2\">Question 2: Train the Model</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this question you will train your, model:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 1</b>: Create a cross entropy criterion function "
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "# Step 1: Create the loss function\n\ncriterion = nn.CrossEntropyLoss()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each."
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "batch_size = 100\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 3</b>: Use the following optimizer to minimize the loss "
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Parameter containing:\ntensor([[ 0.0342, -0.0255,  0.0249,  ...,  0.0130, -0.0365, -0.0426],\n        [ 0.0411, -0.0204,  0.0384,  ...,  0.0156, -0.0340,  0.0069]],\n       requires_grad=True)\nParameter containing:\ntensor([0.0074, 0.0091], requires_grad=True)\n"
                }
            ],
            "source": "# Verify the parameters whose requires_grad are True\nfor param in model.parameters():\n  if param.requires_grad:\n    print(param)"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Number of items in training set :  30000\nNumber of items in testing set :  10000\n------------------------------\nIteration (train phase) 1/300\nFinished in 6.110520124435425 (s)\n------------------------------\nIteration (train phase) 2/300\nFinished in 12.497721672058105 (s)\n------------------------------\nIteration (train phase) 3/300\nFinished in 19.095232486724854 (s)\n------------------------------\nIteration (train phase) 4/300\nFinished in 25.864897966384888 (s)\n------------------------------\nIteration (train phase) 5/300\nFinished in 32.46548867225647 (s)\n------------------------------\nIteration (train phase) 6/300\nFinished in 39.0147602558136 (s)\n------------------------------\nIteration (train phase) 7/300\nFinished in 45.5710825920105 (s)\n------------------------------\nIteration (train phase) 8/300\nFinished in 52.1403067111969 (s)\n------------------------------\nIteration (train phase) 9/300\nFinished in 58.80852675437927 (s)\n------------------------------\nIteration (train phase) 10/300\nFinished in 65.49220657348633 (s)\n------------------------------\nIteration (train phase) 11/300\nFinished in 72.11736750602722 (s)\n------------------------------\nIteration (train phase) 12/300\nFinished in 78.68362164497375 (s)\n------------------------------\nIteration (train phase) 13/300\nFinished in 85.3758864402771 (s)\n------------------------------\nIteration (train phase) 14/300\nFinished in 92.09141778945923 (s)\n------------------------------\nIteration (train phase) 15/300\nFinished in 98.7392590045929 (s)\n------------------------------\nIteration (train phase) 16/300\nFinished in 105.43900394439697 (s)\n------------------------------\nIteration (train phase) 17/300\nFinished in 112.11188292503357 (s)\n------------------------------\nIteration (train phase) 18/300\nFinished in 118.72268438339233 (s)\n------------------------------\nIteration (train phase) 19/300\nFinished in 125.41785860061646 (s)\n------------------------------\nIteration (train phase) 20/300\nFinished in 132.0944483280182 (s)\n------------------------------\nIteration (train phase) 21/300\nFinished in 138.80156326293945 (s)\n------------------------------\nIteration (train phase) 22/300\nFinished in 145.49331259727478 (s)\n------------------------------\nIteration (train phase) 23/300\nFinished in 152.14502501487732 (s)\n------------------------------\nIteration (train phase) 24/300\nFinished in 158.8124520778656 (s)\n------------------------------\nIteration (train phase) 25/300\nFinished in 165.46836018562317 (s)\n------------------------------\nIteration (train phase) 26/300\nFinished in 172.3035922050476 (s)\n------------------------------\nIteration (train phase) 27/300\nFinished in 179.00443935394287 (s)\n------------------------------\nIteration (train phase) 28/300\nFinished in 185.71389842033386 (s)\n------------------------------\nIteration (train phase) 29/300\nFinished in 192.3650004863739 (s)\n------------------------------\nIteration (train phase) 30/300\nFinished in 199.03991508483887 (s)\n------------------------------\nIteration (train phase) 31/300\nFinished in 205.7696409225464 (s)\n------------------------------\nIteration (train phase) 32/300\nFinished in 212.57696771621704 (s)\n------------------------------\nIteration (train phase) 33/300\nFinished in 219.21217679977417 (s)\n------------------------------\nIteration (train phase) 34/300\nFinished in 225.90803742408752 (s)\n------------------------------\nIteration (train phase) 35/300\nFinished in 232.59643626213074 (s)\n------------------------------\nIteration (train phase) 36/300\nFinished in 239.29784607887268 (s)\n------------------------------\nIteration (train phase) 37/300\nFinished in 246.07837200164795 (s)\n------------------------------\nIteration (train phase) 38/300\nFinished in 252.72208309173584 (s)\n------------------------------\nIteration (train phase) 39/300\nFinished in 259.46423721313477 (s)\n------------------------------\nIteration (train phase) 40/300\nFinished in 266.08900117874146 (s)\n------------------------------\nIteration (train phase) 41/300\nFinished in 272.7992329597473 (s)\n------------------------------\nIteration (train phase) 42/300\nFinished in 279.55959010124207 (s)\n------------------------------\nIteration (train phase) 43/300\nFinished in 286.2657346725464 (s)\n------------------------------\nIteration (train phase) 44/300\nFinished in 292.97893142700195 (s)\n------------------------------\nIteration (train phase) 45/300\nFinished in 299.6906404495239 (s)\n------------------------------\nIteration (train phase) 46/300\nFinished in 306.38306307792664 (s)\n------------------------------\nIteration (train phase) 47/300\nFinished in 313.13728499412537 (s)\n------------------------------\nIteration (train phase) 48/300\nFinished in 319.7664215564728 (s)\n------------------------------\nIteration (train phase) 49/300\nFinished in 326.41083574295044 (s)\n------------------------------\nIteration (train phase) 50/300\nFinished in 333.1654236316681 (s)\n------------------------------\nIteration (train phase) 51/300\nFinished in 339.91299176216125 (s)\n------------------------------\nIteration (train phase) 52/300\nFinished in 346.63371992111206 (s)\n------------------------------\nIteration (train phase) 53/300\nFinished in 353.17005157470703 (s)\n------------------------------\nIteration (train phase) 54/300\nFinished in 359.82670521736145 (s)\n------------------------------\nIteration (train phase) 55/300\nFinished in 366.3647403717041 (s)\n------------------------------\nIteration (train phase) 56/300\nFinished in 373.01070499420166 (s)\n------------------------------\nIteration (train phase) 57/300\nFinished in 379.7072958946228 (s)\n------------------------------\nIteration (train phase) 58/300\nFinished in 386.3994414806366 (s)\n------------------------------\nIteration (train phase) 59/300\nFinished in 392.9989404678345 (s)\n------------------------------\nIteration (train phase) 60/300\nFinished in 399.60744428634644 (s)\n------------------------------\nIteration (train phase) 61/300\nFinished in 406.2885277271271 (s)\n------------------------------\nIteration (train phase) 62/300\nFinished in 412.88378071784973 (s)\n------------------------------\nIteration (train phase) 63/300\nFinished in 419.4233260154724 (s)\n------------------------------\nIteration (train phase) 64/300\nFinished in 426.0289840698242 (s)\n------------------------------\nIteration (train phase) 65/300\nFinished in 432.6823172569275 (s)\n------------------------------\nIteration (train phase) 66/300\nFinished in 439.41798734664917 (s)\n------------------------------\nIteration (train phase) 67/300\nFinished in 446.29842805862427 (s)\n------------------------------\nIteration (train phase) 68/300\nFinished in 453.14716958999634 (s)\n------------------------------\nIteration (train phase) 69/300\nFinished in 460.0451476573944 (s)\n------------------------------\nIteration (train phase) 70/300\nFinished in 466.7768704891205 (s)\n------------------------------\nIteration (train phase) 71/300\nFinished in 473.6777994632721 (s)\n------------------------------\nIteration (train phase) 72/300\nFinished in 480.4193346500397 (s)\n------------------------------\nIteration (train phase) 73/300\nFinished in 487.19020414352417 (s)\n------------------------------\nIteration (train phase) 74/300\nFinished in 493.89741253852844 (s)\n------------------------------\nIteration (train phase) 75/300\nFinished in 500.87328028678894 (s)\n------------------------------\nIteration (train phase) 76/300\nFinished in 507.578245639801 (s)\n------------------------------\nIteration (train phase) 77/300\nFinished in 514.23486161232 (s)\n------------------------------\nIteration (train phase) 78/300\nFinished in 521.0635871887207 (s)\n------------------------------\nIteration (train phase) 79/300\nFinished in 527.7209458351135 (s)\n------------------------------\nIteration (train phase) 80/300\nFinished in 534.4052412509918 (s)\n------------------------------\nIteration (train phase) 81/300\nFinished in 541.1518948078156 (s)\n------------------------------\nIteration (train phase) 82/300\nFinished in 548.0397322177887 (s)\n------------------------------\nIteration (train phase) 83/300\nFinished in 554.7634289264679 (s)\n------------------------------\nIteration (train phase) 84/300\nFinished in 561.4429986476898 (s)\n------------------------------\nIteration (train phase) 85/300\nFinished in 568.109091758728 (s)\n------------------------------\nIteration (train phase) 86/300\nFinished in 574.826226234436 (s)\n------------------------------\nIteration (train phase) 87/300\nFinished in 581.5538442134857 (s)\n------------------------------\nIteration (train phase) 88/300\nFinished in 588.5988669395447 (s)\n------------------------------\nIteration (train phase) 89/300\nFinished in 595.305314540863 (s)\n------------------------------\nIteration (train phase) 90/300\nFinished in 601.9888279438019 (s)\n------------------------------\nIteration (train phase) 91/300\nFinished in 608.5635216236115 (s)\n------------------------------\nIteration (train phase) 92/300\nFinished in 615.2489387989044 (s)\n------------------------------\nIteration (train phase) 93/300\nFinished in 621.951281785965 (s)\n------------------------------\nIteration (train phase) 94/300\nFinished in 628.5692889690399 (s)\n------------------------------\nIteration (train phase) 95/300\nFinished in 635.3727707862854 (s)\n------------------------------\nIteration (train phase) 96/300\nFinished in 642.1994514465332 (s)\n------------------------------\nIteration (train phase) 97/300\nFinished in 648.9232287406921 (s)\n------------------------------\nIteration (train phase) 98/300\nFinished in 655.6655020713806 (s)\n------------------------------\nIteration (train phase) 99/300\nFinished in 662.3636419773102 (s)\n------------------------------\nIteration (train phase) 100/300\nFinished in 669.0749125480652 (s)\n------------------------------\nIteration (train phase) 101/300\nFinished in 675.8388166427612 (s)\n------------------------------\nIteration (train phase) 102/300\nFinished in 683.5118160247803 (s)\n------------------------------\nIteration (train phase) 103/300\nFinished in 690.2303943634033 (s)\n------------------------------\nIteration (train phase) 104/300\nFinished in 696.7977073192596 (s)\n------------------------------\nIteration (train phase) 105/300\nFinished in 703.6777715682983 (s)\n------------------------------\nIteration (train phase) 106/300\nFinished in 710.590943813324 (s)\n------------------------------\nIteration (train phase) 107/300\nFinished in 717.3450863361359 (s)\n------------------------------\nIteration (train phase) 108/300\nFinished in 723.9823825359344 (s)\n------------------------------\nIteration (train phase) 109/300\nFinished in 730.6244230270386 (s)\n------------------------------\nIteration (train phase) 110/300\nFinished in 737.3718826770782 (s)\n------------------------------\nIteration (train phase) 111/300\nFinished in 744.1098067760468 (s)\n------------------------------\nIteration (train phase) 112/300\nFinished in 750.8627507686615 (s)\n------------------------------\nIteration (train phase) 113/300\nFinished in 757.6565523147583 (s)\n------------------------------\nIteration (train phase) 114/300\nFinished in 764.4460442066193 (s)\n------------------------------\nIteration (train phase) 115/300\nFinished in 771.1823499202728 (s)\n------------------------------\nIteration (train phase) 116/300\nFinished in 777.7758445739746 (s)\n------------------------------\nIteration (train phase) 117/300\nFinished in 784.401695728302 (s)\n------------------------------\nIteration (train phase) 118/300\nFinished in 791.0974378585815 (s)\n------------------------------\nIteration (train phase) 119/300\nFinished in 797.8653872013092 (s)\n------------------------------\nIteration (train phase) 120/300\nFinished in 804.6463153362274 (s)\n------------------------------\nIteration (train phase) 121/300\nFinished in 811.4451532363892 (s)\n------------------------------\nIteration (train phase) 122/300\nFinished in 818.2548444271088 (s)\n------------------------------\nIteration (train phase) 123/300\nFinished in 824.9918823242188 (s)\n------------------------------\nIteration (train phase) 124/300\nFinished in 831.8321347236633 (s)\n------------------------------\nIteration (train phase) 125/300\nFinished in 838.4732689857483 (s)\n------------------------------\nIteration (train phase) 126/300\nFinished in 845.2437722682953 (s)\n------------------------------\nIteration (train phase) 127/300\nFinished in 851.9904193878174 (s)\n------------------------------\nIteration (train phase) 128/300\nFinished in 858.5792808532715 (s)\n------------------------------\nIteration (train phase) 129/300\nFinished in 865.2195177078247 (s)\n------------------------------\nIteration (train phase) 130/300\nFinished in 871.9778385162354 (s)\n------------------------------\nIteration (train phase) 131/300\nFinished in 878.7209763526917 (s)\n------------------------------\nIteration (train phase) 132/300\nFinished in 885.3891055583954 (s)\n------------------------------\nIteration (train phase) 133/300\nFinished in 892.1170797348022 (s)\n------------------------------\nIteration (train phase) 134/300\nFinished in 898.8463597297668 (s)\n------------------------------\nIteration (train phase) 135/300\nFinished in 905.4978580474854 (s)\n------------------------------\nIteration (train phase) 136/300\nFinished in 912.1300683021545 (s)\n------------------------------\nIteration (train phase) 137/300\nFinished in 918.8780989646912 (s)\n------------------------------\nIteration (train phase) 138/300\nFinished in 925.514232635498 (s)\n------------------------------\nIteration (train phase) 139/300\nFinished in 932.2881405353546 (s)\n------------------------------\nIteration (train phase) 140/300\nFinished in 939.0088877677917 (s)\n------------------------------\nIteration (train phase) 141/300\nFinished in 945.813098192215 (s)\n------------------------------\nIteration (train phase) 142/300\nFinished in 952.5146222114563 (s)\n------------------------------\nIteration (train phase) 143/300\nFinished in 959.2678711414337 (s)\n------------------------------\nIteration (train phase) 144/300\nFinished in 966.070151090622 (s)\n------------------------------\nIteration (train phase) 145/300\nFinished in 972.8230450153351 (s)\n------------------------------\nIteration (train phase) 146/300\nFinished in 979.5600001811981 (s)\n------------------------------\nIteration (train phase) 147/300\nFinished in 986.3409073352814 (s)\n------------------------------\nIteration (train phase) 148/300\nFinished in 993.092383146286 (s)\n------------------------------\nIteration (train phase) 149/300\nFinished in 999.8102276325226 (s)\n------------------------------\nIteration (train phase) 150/300\nFinished in 1006.5612654685974 (s)\n------------------------------\nIteration (train phase) 151/300\nFinished in 1013.466392993927 (s)\n------------------------------\nIteration (train phase) 152/300\nFinished in 1020.0517580509186 (s)\n------------------------------\nIteration (train phase) 153/300\nFinished in 1026.634022951126 (s)\n------------------------------\nIteration (train phase) 154/300\nFinished in 1033.3515617847443 (s)\n------------------------------\nIteration (train phase) 155/300\nFinished in 1040.057627916336 (s)\n------------------------------\nIteration (train phase) 156/300\nFinished in 1046.6603496074677 (s)\n------------------------------\nIteration (train phase) 157/300\nFinished in 1053.376582145691 (s)\n------------------------------\nIteration (train phase) 158/300\nFinished in 1060.0051891803741 (s)\n------------------------------\nIteration (train phase) 159/300\nFinished in 1066.8332056999207 (s)\n------------------------------\nIteration (train phase) 160/300\nFinished in 1073.6717104911804 (s)\n------------------------------\nIteration (train phase) 161/300\nFinished in 1080.3975856304169 (s)\n------------------------------\nIteration (train phase) 162/300\nFinished in 1087.2248854637146 (s)\n------------------------------\nIteration (train phase) 163/300\nFinished in 1093.9633655548096 (s)\n------------------------------\nIteration (train phase) 164/300\nFinished in 1101.120977640152 (s)\n------------------------------\nIteration (train phase) 165/300\nFinished in 1107.8157391548157 (s)\n------------------------------\nIteration (train phase) 166/300\nFinished in 1114.537981748581 (s)\n------------------------------\nIteration (train phase) 167/300\nFinished in 1121.3430235385895 (s)\n------------------------------\nIteration (train phase) 168/300\nFinished in 1128.1287384033203 (s)\n------------------------------\nIteration (train phase) 169/300\nFinished in 1134.8714056015015 (s)\n------------------------------\nIteration (train phase) 170/300\nFinished in 1141.570707321167 (s)\n------------------------------\nIteration (train phase) 171/300\nFinished in 1148.2883241176605 (s)\n------------------------------\nIteration (train phase) 172/300\nFinished in 1154.9873688220978 (s)\n------------------------------\nIteration (train phase) 173/300\nFinished in 1161.796528339386 (s)\n------------------------------\nIteration (train phase) 174/300\nFinished in 1168.6563701629639 (s)\n------------------------------\nIteration (train phase) 175/300\nFinished in 1175.5382404327393 (s)\n------------------------------\nIteration (train phase) 176/300\nFinished in 1182.287493467331 (s)\n------------------------------\nIteration (train phase) 177/300\nFinished in 1189.0294215679169 (s)\n------------------------------\nIteration (train phase) 178/300\nFinished in 1195.775050163269 (s)\n------------------------------\nIteration (train phase) 179/300\nFinished in 1202.38734292984 (s)\n------------------------------\nIteration (train phase) 180/300\nFinished in 1209.1651945114136 (s)\n------------------------------\nIteration (train phase) 181/300\nFinished in 1215.975937128067 (s)\n------------------------------\nIteration (train phase) 182/300\nFinished in 1222.6972317695618 (s)\n------------------------------\nIteration (train phase) 183/300\nFinished in 1229.7558579444885 (s)\n------------------------------\nIteration (train phase) 184/300\nFinished in 1236.4551830291748 (s)\n------------------------------\nIteration (train phase) 185/300\nFinished in 1243.1979570388794 (s)\n------------------------------\nIteration (train phase) 186/300\nFinished in 1250.00315451622 (s)\n------------------------------\nIteration (train phase) 187/300\nFinished in 1256.6569330692291 (s)\n------------------------------\nIteration (train phase) 188/300\nFinished in 1263.5317933559418 (s)\n------------------------------\nIteration (train phase) 189/300\nFinished in 1270.2357366085052 (s)\n------------------------------\nIteration (train phase) 190/300\nFinished in 1277.0749781131744 (s)\n------------------------------\nIteration (train phase) 191/300\nFinished in 1283.8685522079468 (s)\n------------------------------\nIteration (train phase) 192/300\nFinished in 1290.4782302379608 (s)\n------------------------------\nIteration (train phase) 193/300\nFinished in 1297.1937403678894 (s)\n------------------------------\nIteration (train phase) 194/300\nFinished in 1303.866569519043 (s)\n------------------------------\nIteration (train phase) 195/300\nFinished in 1310.6744878292084 (s)\n------------------------------\nIteration (train phase) 196/300\nFinished in 1317.459870815277 (s)\n------------------------------\nIteration (train phase) 197/300\nFinished in 1324.1407420635223 (s)\n------------------------------\nIteration (train phase) 198/300\nFinished in 1331.3027184009552 (s)\n------------------------------\nIteration (train phase) 199/300\nFinished in 1338.0703072547913 (s)\n------------------------------\nIteration (train phase) 200/300\nFinished in 1344.7227761745453 (s)\n------------------------------\nIteration (train phase) 201/300\nFinished in 1351.4728462696075 (s)\n------------------------------\nIteration (train phase) 202/300\nFinished in 1358.1103162765503 (s)\n------------------------------\nIteration (train phase) 203/300\nFinished in 1364.86923289299 (s)\n------------------------------\nIteration (train phase) 204/300\nFinished in 1371.7772510051727 (s)\n------------------------------\nIteration (train phase) 205/300\nFinished in 1378.4546613693237 (s)\n------------------------------\nIteration (train phase) 206/300\nFinished in 1385.1002357006073 (s)\n------------------------------\nIteration (train phase) 207/300\nFinished in 1391.8228018283844 (s)\n------------------------------\nIteration (train phase) 208/300\nFinished in 1398.4791896343231 (s)\n------------------------------\nIteration (train phase) 209/300\nFinished in 1405.2671291828156 (s)\n------------------------------\nIteration (train phase) 210/300\nFinished in 1411.963346004486 (s)\n------------------------------\nIteration (train phase) 211/300\nFinished in 1418.668779373169 (s)\n------------------------------\nIteration (train phase) 212/300\nFinished in 1425.3824210166931 (s)\n------------------------------\nIteration (train phase) 213/300\nFinished in 1432.1727228164673 (s)\n------------------------------\nIteration (train phase) 214/300\nFinished in 1438.9516153335571 (s)\n------------------------------\nIteration (train phase) 215/300\nFinished in 1445.6407918930054 (s)\n------------------------------\nIteration (train phase) 216/300\nFinished in 1452.3632247447968 (s)\n------------------------------\nIteration (train phase) 217/300\nFinished in 1459.2333686351776 (s)\n------------------------------\nIteration (train phase) 218/300\nFinished in 1466.6043000221252 (s)\n------------------------------\nIteration (train phase) 219/300\nFinished in 1473.9730467796326 (s)\n------------------------------\nIteration (train phase) 220/300\nFinished in 1481.443749666214 (s)\n------------------------------\nIteration (train phase) 221/300\nFinished in 1489.0426843166351 (s)\n------------------------------\nIteration (train phase) 222/300\nFinished in 1496.4073133468628 (s)\n------------------------------\nIteration (train phase) 223/300\nFinished in 1503.657356262207 (s)\n------------------------------\nIteration (train phase) 224/300\nFinished in 1510.8580901622772 (s)\n------------------------------\nIteration (train phase) 225/300\nFinished in 1518.0897769927979 (s)\n------------------------------\nIteration (train phase) 226/300\nFinished in 1525.8282136917114 (s)\n------------------------------\nIteration (train phase) 227/300\nFinished in 1533.1806647777557 (s)\n------------------------------\nIteration (train phase) 228/300\nFinished in 1540.3788545131683 (s)\n------------------------------\nIteration (train phase) 229/300\nFinished in 1547.7142848968506 (s)\n------------------------------\nIteration (train phase) 230/300\nFinished in 1554.9793627262115 (s)\n------------------------------\nIteration (train phase) 231/300\nFinished in 1562.3462436199188 (s)\n------------------------------\nIteration (train phase) 232/300\nFinished in 1569.7473652362823 (s)\n------------------------------\nIteration (train phase) 233/300\nFinished in 1577.3721511363983 (s)\n------------------------------\nIteration (train phase) 234/300\nFinished in 1584.6314189434052 (s)\n------------------------------\nIteration (train phase) 235/300\nFinished in 1592.0222625732422 (s)\n------------------------------\nIteration (train phase) 236/300\nFinished in 1599.4102165699005 (s)\n------------------------------\nIteration (train phase) 237/300\nFinished in 1606.7027914524078 (s)\n------------------------------\nIteration (train phase) 238/300\nFinished in 1613.921704530716 (s)\n------------------------------\nIteration (train phase) 239/300\nFinished in 1621.2311441898346 (s)\n------------------------------\nIteration (train phase) 240/300\nFinished in 1628.586269378662 (s)\n------------------------------\nIteration (train phase) 241/300\nFinished in 1635.9981360435486 (s)\n------------------------------\nIteration (train phase) 242/300\nFinished in 1643.4736981391907 (s)\n------------------------------\nIteration (train phase) 243/300\nFinished in 1650.94389128685 (s)\n------------------------------\nIteration (train phase) 244/300\nFinished in 1658.4207963943481 (s)\n------------------------------\nIteration (train phase) 245/300\nFinished in 1665.746241569519 (s)\n------------------------------\nIteration (train phase) 246/300\nFinished in 1673.0407710075378 (s)\n------------------------------\nIteration (train phase) 247/300\nFinished in 1680.2217314243317 (s)\n------------------------------\nIteration (train phase) 248/300\nFinished in 1687.6392381191254 (s)\n------------------------------\nIteration (train phase) 249/300\nFinished in 1694.9240508079529 (s)\n------------------------------\nIteration (train phase) 250/300\nFinished in 1702.2755858898163 (s)\n------------------------------\nIteration (train phase) 251/300\nFinished in 1709.6763615608215 (s)\n------------------------------\nIteration (train phase) 252/300\nFinished in 1716.9499952793121 (s)\n------------------------------\nIteration (train phase) 253/300\nFinished in 1724.4334409236908 (s)\n------------------------------\nIteration (train phase) 254/300\nFinished in 1731.7829778194427 (s)\n------------------------------\nIteration (train phase) 255/300\nFinished in 1739.20610165596 (s)\n------------------------------\nIteration (train phase) 256/300\nFinished in 1746.5384199619293 (s)\n------------------------------\nIteration (train phase) 257/300\nFinished in 1753.8645708560944 (s)\n------------------------------\nIteration (train phase) 258/300\nFinished in 1761.1244449615479 (s)\n------------------------------\nIteration (train phase) 259/300\nFinished in 1768.5514068603516 (s)\n------------------------------\nIteration (train phase) 260/300\nFinished in 1775.8184652328491 (s)\n------------------------------\nIteration (train phase) 261/300\nFinished in 1783.116852760315 (s)\n------------------------------\nIteration (train phase) 262/300\nFinished in 1790.4088883399963 (s)\n------------------------------\nIteration (train phase) 263/300\nFinished in 1797.800055027008 (s)\n------------------------------\nIteration (train phase) 264/300\nFinished in 1805.1842033863068 (s)\n------------------------------\nIteration (train phase) 265/300\nFinished in 1812.5221219062805 (s)\n------------------------------\nIteration (train phase) 266/300\nFinished in 1820.0301756858826 (s)\n------------------------------\nIteration (train phase) 267/300\nFinished in 1827.3576436042786 (s)\n------------------------------\nIteration (train phase) 268/300\nFinished in 1834.7378158569336 (s)\n------------------------------\nIteration (train phase) 269/300\nFinished in 1842.2199380397797 (s)\n------------------------------\nIteration (train phase) 270/300\nFinished in 1849.6036269664764 (s)\n------------------------------\nIteration (train phase) 271/300\nFinished in 1856.9211966991425 (s)\n------------------------------\nIteration (train phase) 272/300\nFinished in 1864.3054814338684 (s)\n------------------------------\nIteration (train phase) 273/300\nFinished in 1871.5668048858643 (s)\n------------------------------\nIteration (train phase) 274/300\nFinished in 1878.9643392562866 (s)\n------------------------------\nIteration (train phase) 275/300\nFinished in 1886.4471521377563 (s)\n------------------------------\nIteration (train phase) 276/300\nFinished in 1893.8914737701416 (s)\n------------------------------\nIteration (train phase) 277/300\nFinished in 1901.2600555419922 (s)\n------------------------------\nIteration (train phase) 278/300\nFinished in 1908.5532429218292 (s)\n------------------------------\nIteration (train phase) 279/300\nFinished in 1916.0528349876404 (s)\n------------------------------\nIteration (train phase) 280/300\nFinished in 1923.3081266880035 (s)\n------------------------------\nIteration (train phase) 281/300\nFinished in 1930.6412580013275 (s)\n------------------------------\nIteration (train phase) 282/300\nFinished in 1938.0359015464783 (s)\n------------------------------\nIteration (train phase) 283/300\nFinished in 1945.4128386974335 (s)\n------------------------------\nIteration (train phase) 284/300\nFinished in 1952.9035212993622 (s)\n------------------------------\nIteration (train phase) 285/300\nFinished in 1960.3047246932983 (s)\n------------------------------\nIteration (train phase) 286/300\nFinished in 1967.6289298534393 (s)\n------------------------------\nIteration (train phase) 287/300\nFinished in 1975.0226995944977 (s)\n------------------------------\nIteration (train phase) 288/300\nFinished in 1982.279286146164 (s)\n------------------------------\nIteration (train phase) 289/300\nFinished in 1989.6821570396423 (s)\n------------------------------\nIteration (train phase) 290/300\nFinished in 1996.961757659912 (s)\n------------------------------\nIteration (train phase) 291/300\nFinished in 2004.2282009124756 (s)\n------------------------------\nIteration (train phase) 292/300\nFinished in 2011.538169145584 (s)\n------------------------------\nIteration (train phase) 293/300\nFinished in 2018.9047334194183 (s)\n------------------------------\nIteration (train phase) 294/300\nFinished in 2026.3389563560486 (s)\n------------------------------\nIteration (train phase) 295/300\nFinished in 2033.6253061294556 (s)\n------------------------------\nIteration (train phase) 296/300\nFinished in 2040.8829596042633 (s)\n------------------------------\nIteration (train phase) 297/300\nFinished in 2048.194071292877 (s)\n------------------------------\nIteration (train phase) 298/300\nFinished in 2055.584537267685 (s)\n------------------------------\nIteration (train phase) 299/300\nFinished in 2062.973346233368 (s)\n------------------------------\nIteration (train phase) 300/300\nFinished in 2070.339840888977 (s)\n------------------------------\nIteration (validation phase) 1/100\nFinished in 2077.28227353096 (s)\n------------------------------\nIteration (validation phase) 2/100\nFinished in 2084.1202244758606 (s)\n------------------------------\nIteration (validation phase) 3/100\nFinished in 2091.0835058689117 (s)\n------------------------------\nIteration (validation phase) 4/100\nFinished in 2097.992784500122 (s)\n------------------------------\nIteration (validation phase) 5/100\nFinished in 2104.8405787944794 (s)\n------------------------------\nIteration (validation phase) 6/100\nFinished in 2111.6288044452667 (s)\n------------------------------\nIteration (validation phase) 7/100\nFinished in 2118.4559800624847 (s)\n------------------------------\nIteration (validation phase) 8/100\nFinished in 2125.375375032425 (s)\n------------------------------\nIteration (validation phase) 9/100\nFinished in 2132.3465588092804 (s)\n------------------------------\nIteration (validation phase) 10/100\nFinished in 2139.347670316696 (s)\n------------------------------\nIteration (validation phase) 11/100\nFinished in 2146.218586206436 (s)\n------------------------------\nIteration (validation phase) 12/100\nFinished in 2153.1478991508484 (s)\n------------------------------\nIteration (validation phase) 13/100\nFinished in 2160.0345141887665 (s)\n------------------------------\nIteration (validation phase) 14/100\nFinished in 2167.0283513069153 (s)\n------------------------------\nIteration (validation phase) 15/100\nFinished in 2173.985092639923 (s)\n------------------------------\nIteration (validation phase) 16/100\nFinished in 2180.833265066147 (s)\n------------------------------\nIteration (validation phase) 17/100\nFinished in 2187.8471064567566 (s)\n------------------------------\nIteration (validation phase) 18/100\nFinished in 2194.6788306236267 (s)\n------------------------------\nIteration (validation phase) 19/100\nFinished in 2201.6122148036957 (s)\n------------------------------\nIteration (validation phase) 20/100\nFinished in 2208.4969630241394 (s)\n------------------------------\nIteration (validation phase) 21/100\nFinished in 2215.4295015335083 (s)\n------------------------------\nIteration (validation phase) 22/100\nFinished in 2222.3328108787537 (s)\n------------------------------\nIteration (validation phase) 23/100\nFinished in 2229.2271206378937 (s)\n------------------------------\nIteration (validation phase) 24/100\nFinished in 2236.1583421230316 (s)\n------------------------------\nIteration (validation phase) 25/100\nFinished in 2243.0253381729126 (s)\n------------------------------\nIteration (validation phase) 26/100\nFinished in 2249.9986474514008 (s)\n------------------------------\nIteration (validation phase) 27/100\nFinished in 2256.790241241455 (s)\n------------------------------\nIteration (validation phase) 28/100\nFinished in 2263.729804992676 (s)\n------------------------------\nIteration (validation phase) 29/100\nFinished in 2270.6656234264374 (s)\n------------------------------\nIteration (validation phase) 30/100\nFinished in 2277.4639732837677 (s)\n------------------------------\nIteration (validation phase) 31/100\nFinished in 2284.3453075885773 (s)\n------------------------------\nIteration (validation phase) 32/100\nFinished in 2291.155797958374 (s)\n------------------------------\nIteration (validation phase) 33/100\nFinished in 2298.0197134017944 (s)\n------------------------------\nIteration (validation phase) 34/100\nFinished in 2304.8569917678833 (s)\n------------------------------\nIteration (validation phase) 35/100\nFinished in 2311.770970106125 (s)\n------------------------------\nIteration (validation phase) 36/100\nFinished in 2318.648773431778 (s)\n------------------------------\nIteration (validation phase) 37/100\nFinished in 2325.3896338939667 (s)\n------------------------------\nIteration (validation phase) 38/100\nFinished in 2332.2026374340057 (s)\n------------------------------\nIteration (validation phase) 39/100\nFinished in 2339.072658777237 (s)\n------------------------------\nIteration (validation phase) 40/100\nFinished in 2345.803546667099 (s)\n------------------------------\nIteration (validation phase) 41/100\nFinished in 2352.5865137577057 (s)\n------------------------------\nIteration (validation phase) 42/100\nFinished in 2359.4893786907196 (s)\n------------------------------\nIteration (validation phase) 43/100\nFinished in 2366.2587361335754 (s)\n------------------------------\nIteration (validation phase) 44/100\nFinished in 2373.1380712985992 (s)\n------------------------------\nIteration (validation phase) 45/100\nFinished in 2380.0165526866913 (s)\n------------------------------\nIteration (validation phase) 46/100\nFinished in 2386.7947523593903 (s)\n------------------------------\nIteration (validation phase) 47/100\nFinished in 2393.602108478546 (s)\n------------------------------\nIteration (validation phase) 48/100\nFinished in 2400.33952832222 (s)\n------------------------------\nIteration (validation phase) 49/100\nFinished in 2407.1084439754486 (s)\n------------------------------\nIteration (validation phase) 50/100\nFinished in 2413.8693718910217 (s)\n------------------------------\nIteration (validation phase) 51/100\nFinished in 2420.7872273921967 (s)\n------------------------------\nIteration (validation phase) 52/100\nFinished in 2427.7557027339935 (s)\n------------------------------\nIteration (validation phase) 53/100\nFinished in 2434.6412818431854 (s)\n------------------------------\nIteration (validation phase) 54/100\nFinished in 2441.5241346359253 (s)\n------------------------------\nIteration (validation phase) 55/100\nFinished in 2448.2708687782288 (s)\n------------------------------\nIteration (validation phase) 56/100\nFinished in 2455.0686087608337 (s)\n------------------------------\nIteration (validation phase) 57/100\nFinished in 2461.9353625774384 (s)\n------------------------------\nIteration (validation phase) 58/100\nFinished in 2468.6984481811523 (s)\n------------------------------\nIteration (validation phase) 59/100\nFinished in 2475.477546930313 (s)\n------------------------------\nIteration (validation phase) 60/100\nFinished in 2482.3347992897034 (s)\n------------------------------\nIteration (validation phase) 61/100\nFinished in 2489.1344125270844 (s)\n------------------------------\nIteration (validation phase) 62/100\nFinished in 2496.0541381835938 (s)\n------------------------------\nIteration (validation phase) 63/100\nFinished in 2502.9921424388885 (s)\n------------------------------\nIteration (validation phase) 64/100\nFinished in 2509.8807525634766 (s)\n------------------------------\nIteration (validation phase) 65/100\nFinished in 2516.8029429912567 (s)\n------------------------------\nIteration (validation phase) 66/100\nFinished in 2523.5535542964935 (s)\n------------------------------\nIteration (validation phase) 67/100\nFinished in 2530.425393819809 (s)\n------------------------------\nIteration (validation phase) 68/100\nFinished in 2537.323363304138 (s)\n------------------------------\nIteration (validation phase) 69/100\nFinished in 2544.16926074028 (s)\n------------------------------\nIteration (validation phase) 70/100\nFinished in 2551.4702067375183 (s)\n------------------------------\nIteration (validation phase) 71/100\nFinished in 2558.395974636078 (s)\n------------------------------\nIteration (validation phase) 72/100\nFinished in 2565.3018567562103 (s)\n------------------------------\nIteration (validation phase) 73/100\nFinished in 2572.111503601074 (s)\n------------------------------\nIteration (validation phase) 74/100\nFinished in 2578.9354577064514 (s)\n------------------------------\nIteration (validation phase) 75/100\nFinished in 2585.8993496894836 (s)\n------------------------------\nIteration (validation phase) 76/100\nFinished in 2592.691181898117 (s)\n------------------------------\nIteration (validation phase) 77/100\nFinished in 2599.6565747261047 (s)\n------------------------------\nIteration (validation phase) 78/100\nFinished in 2606.4464116096497 (s)\n------------------------------\nIteration (validation phase) 79/100\nFinished in 2613.3367264270782 (s)\n------------------------------\nIteration (validation phase) 80/100\nFinished in 2620.176944255829 (s)\n------------------------------\nIteration (validation phase) 81/100\nFinished in 2627.0278146266937 (s)\n------------------------------\nIteration (validation phase) 82/100\nFinished in 2633.790049791336 (s)\n------------------------------\nIteration (validation phase) 83/100\nFinished in 2640.494190454483 (s)\n------------------------------\nIteration (validation phase) 84/100\nFinished in 2647.3174500465393 (s)\n------------------------------\nIteration (validation phase) 85/100\nFinished in 2654.1660611629486 (s)\n------------------------------\nIteration (validation phase) 86/100\nFinished in 2661.0324466228485 (s)\n------------------------------\nIteration (validation phase) 87/100\nFinished in 2667.9707436561584 (s)\n------------------------------\nIteration (validation phase) 88/100\nFinished in 2675.0246682167053 (s)\n------------------------------\nIteration (validation phase) 89/100\nFinished in 2681.901611804962 (s)\n------------------------------\nIteration (validation phase) 90/100\nFinished in 2688.7986102104187 (s)\n------------------------------\nIteration (validation phase) 91/100\nFinished in 2695.709557533264 (s)\n------------------------------\nIteration (validation phase) 92/100\nFinished in 2702.4541726112366 (s)\n------------------------------\nIteration (validation phase) 93/100\nFinished in 2709.42364692688 (s)\n------------------------------\nIteration (validation phase) 94/100\nFinished in 2716.325987815857 (s)\n------------------------------\nIteration (validation phase) 95/100\nFinished in 2723.227430343628 (s)\n------------------------------\nIteration (validation phase) 96/100\nFinished in 2730.0794775485992 (s)\n------------------------------\nIteration (validation phase) 97/100\nFinished in 2736.906327724457 (s)\n------------------------------\nIteration (validation phase) 98/100\nFinished in 2743.8844680786133 (s)\n------------------------------\nIteration (validation phase) 99/100\nFinished in 2750.720194339752 (s)\n------------------------------\nIteration (validation phase) 100/100\nFinished in 2757.511766433716 (s)\nEpoch 1 - accuracy: 0.995\n------------------------------------------------------------------------\n"
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'model_path' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-20-092975abe612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mmodel_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"resnet18_trained_model_epoch_{}.pth\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'model_path' is not defined"
                    ]
                }
            ],
            "source": "n_epochs = 1\nloss_list = []\naccuracy_list = []\naccuracy = 0\ncorrect = 0\nN_test = len(validation_dataset)\nN_train = len(train_dataset)\nstart_time = time.time()\n#n_epochs\n\nprint(\"Number of items in training set : \", N_train)\nprint(\"Number of items in testing set : \", N_test)\n\nrunning_loss = 0\nstart_time = time.time()\nfor epoch in range(n_epochs):\n    for i, (x, y) in enumerate(train_loader):        \n        print('-' * 30)\n        print('Iteration (train phase) {}/{}'.format(i+1, int(N_train/batch_size)))\n\n            \n        # set model to train \n        model.train() \n        \n        # clear gradient \n        optimizer.zero_grad()\n     \n        # make a prediction \n        z = model(x)\n   \n        # calculate loss \n        loss = criterion(z, y) \n        # loss.requires_grad = True\n    \n        # calculate gradients of parameters \n        loss.backward()\n        \n        # update parameters \n        optimizer.step()\n        \n        loss_list.append(loss.data)\n        print(\"Finished in {} (s)\".format(time.time()-start_time))\n    # end for\n        \n    correct=0\n    for i, (x_test, y_test) in enumerate(validation_loader):\n        print('-' * 30)\n        print('Iteration (validation phase) {}/{}'.format(i+1, int(N_test/batch_size)))\n    \n        \n        # set model to eval \n        model.eval()\n       \n        # make a prediction \n        z = model(x_test)\n        \n        # find max \n        _, yhat = torch.max(z.data, 1)\n       \n       \n        #Calculate misclassified  samples in mini-batch \n        #hint +=(yhat==y_test).sum().item()\n        correct += (yhat==y_test).sum().item()  \n        \n        print(\"Finished in {} (s)\".format(time.time()-start_time))\n    # end for\n    \n    accuracy=correct/N_test\n    print(\"Epoch %d - accuracy: %.3f\" % (epoch+1, accuracy))\n    \n    accuracy_list.append(accuracy)\n    print(\"-\" * 72)\n    \n    # Save model\n    model_file_path = model_path + \"resnet18_trained_model_epoch_{}.pth\".format(epoch+1)\n    torch.save(model.state_dict(), model_file_path)\n    \n    # Duration for epoch\n    print(\"Finished epoch {} in {} (s).\".format(epoch+1, time.time()-start_time))\n# end for\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.9946"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "accuracy"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "plt.plot(loss_list)\nplt.xlabel(\"iteration\")\nplt.ylabel(\"loss\")\nplt.show()\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Identify the first four misclassified samples using the validation data:</b>"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Sample : 110; Expected Label: tensor([1]); Obtained Label: tensor([0])\nSample : 228; Expected Label: tensor([1]); Obtained Label: tensor([0])\nSample : 634; Expected Label: tensor([1]); Obtained Label: tensor([0])\nSample : 748; Expected Label: tensor([1]); Obtained Label: tensor([0])\n"
                }
            ],
            "source": "            count = 0\nmax_num_of_items = 4  # first four mis-classified samples\nvalidation_loader_batch_one = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)\n\nfor i, (x_test, y_test) in enumerate(validation_loader_batch_one):\n    # set model to eval\n    model.eval()\n    \n    # make a prediction\n    z = model(x_test)\n    \n    # find max\n    _, yhat = torch.max(z.data, 1)\n    \n    # print mis-classified samples\n    if yhat != y_test:\n        print(\"Sample : {}; Expected Label: {}; Obtained Label: {}\".format(str(i), str(y_test), str(yhat)))\n        count += 1\n        if count >= max_num_of_items:\n                        break\n    # end if\n# end for"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html\"> CLICK HERE </a> Click here to see how to share your notebook."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>About the Authors:</h2> \n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}